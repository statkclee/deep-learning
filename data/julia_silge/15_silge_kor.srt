1
00:00:01,120 --> 00:00:08,639
안녕하세요 제 이름은 줄리아 실지입니다. 저는 RStudio의 데이터 과학자이자 소프트웨어 엔지니어입니다.

2
00:00:06,080 --> 00:00:13,519
그리고 한국의 R 사용자 그룹의 주최자에게 감사의 말을 전하고 싶습니다.

3
00:00:11,200 --> 00:00:18,080
나를 가진 것에 대해 너무 많이. 오늘은 너에게 말을 걸

4
00:00:15,519 --> 00:00:24,000
오늘 특별히 제작에 대해 이야기하게 되어 매우 기쁩니다.

5
00:00:21,119 --> 00:00:29,359
몇 가지 이유로 텍스트 데이터에서 기계 학습을 위한 기능

6
00:00:27,199 --> 00:00:34,480
우리가 텍스트 데이터를 취하기 위해 무엇을 하는지 더 잘 이해하기

7
00:00:31,679 --> 00:00:36,880
그런 다음 적절하게 만들기 위해

8
00:00:34,480 --> 00:00:42,879
기계 학습 알고리즘에 대한 입력으로 많은 이점이 있습니다.

9
00:00:39,680 --> 00:00:45,039
둘 다 직접 준비하는 경우

10
00:00:42,879 --> 00:00:50,719
모델을 훈련시키거나 일부 텍스트 분석 프로젝트를 시작하는 경우

11
00:00:48,399 --> 00:00:55,440
또는 모델의 동작을 이해하려는 경우

12
00:00:52,800 --> 00:01:00,480
데이터 과학자로서 우리가 하는 일과 같은 방식으로 상호 작용하고 있습니다.

13
00:00:57,920 --> 00:01:06,640
또는 우리의 일상 생활에서 점점 더

14
00:01:03,359 --> 00:01:09,360
따라서 감독 또는 감독되지 않은 텍스트에 대한 모델을 구축할 때

15
00:01:06,640 --> 00:01:15,759
우리는 무언가로 시작합니다

16
00:01:11,600 --> 00:01:17,600
이것은 몇 가지 예제 텍스트 데이터입니다.

17
00:01:15,759 --> 00:01:21,040
내가 몇 번 사용하는 동안

18
00:01:17,600 --> 00:01:24,560
일부 동물을 설명하는 이 이야기

19
00:01:21,040 --> 00:01:26,720
일부 텍스트 데이터를 사용하고 있으므로

20
00:01:24,560 --> 00:01:30,960
당신은 나에게 영어로 알고

21
00:01:26,720 --> 00:01:34,400
스피커는 다음과 같이 친숙해 보입니다.

22
00:01:30,960 --> 00:01:36,720
나는 인간을 사용하는 사람으로서

23
00:01:34,400 --> 00:01:39,520
언어를 사용하여 이것을 보고 할 수 있습니다.

24
00:01:36,720 --> 00:01:43,920
그것을 읽으십시오 나는 큰 소리로 말할 수 있고 나는 이해할 수 있습니다

25
00:01:41,280 --> 00:01:45,759
나는 그것이 무엇을 의미하는지 해석할 수 있다

26
00:01:43,920 --> 00:01:50,000
그래서 이런 종류의 데이터는 이런 종류의

27
00:01:45,759 --> 00:01:51,200
자연어 데이터가 생성되고 있습니다.

28
00:01:50,000 --> 00:01:56,880
모든 종류의 언어로 항상

29
00:01:53,600 --> 00:01:59,840
모든 종류의 상황에서

30
00:01:56,880 --> 00:02:05,040
금융 기술 분야 의료 분야에서 일하는지 여부

31
00:02:02,640 --> 00:02:08,479
기본적으로 어떤 종류의 조직이든

32
00:02:05,040 --> 00:02:11,920
일종의 텍스트 데이터가 생성되고 있습니다.

33
00:02:09,360 --> 00:02:17,599
고객에 의한 고객에 의한 내부 이해관계자에 의한

34
00:02:15,200 --> 00:02:24,319
설문 조사에 참여하는 사람들에 의해 기업 내부

35
00:02:20,000 --> 00:02:26,720
비즈니스 프로세스를 통해 소셜 미디어를 통해

36
00:02:24,319 --> 00:02:29,200
그리고 이 모든 자연어에서

37
00:02:26,720 --> 00:02:33,519
정보가 숨어있다

38
00:02:30,879 --> 00:02:35,360
더 나은 결정을 내리는 데 사용할 수 있는 텍스트 데이터

39
00:02:33,519 --> 00:02:44,319
그러나 컴퓨터는 이것을 보고 수행하는 데 능숙하지 않습니다.

40
00:02:41,280 --> 00:02:47,440
다음과 같이 표현되는 언어에 대한 수학

41
00:02:45,440 --> 00:02:50,560
대신 언어는

42
00:02:47,440 --> 00:02:53,680
극적으로 어떤 종류의

43
00:02:50,560 --> 00:02:55,440
기계 판독 가능한 숫자 표현

44
00:02:53,680 --> 00:02:57,280
그것이 내가 무엇인지 더 많이 보인다

45
00:02:55,440 --> 00:02:59,760
준비를 위해 여기 화면에 표시

46
00:02:57,280 --> 00:03:01,840
거의 모든 종류의 모델에 대해

47
00:02:59,760 --> 00:03:05,040
그래서 나는 상당한 시간을 일했다.

48
00:03:01,840 --> 00:03:07,680
사람들이 할 수 있는 소프트웨어

49
00:03:05,040 --> 00:03:15,120
탐색적 데이터 분석, 시각화, 요약

50
00:03:11,760 --> 00:03:17,920
깔끔한 텍스트 데이터와 같은 작업

51
00:03:15,120 --> 00:03:22,159
행당 하나의 관찰이 있는 형식

52
00:03:19,040 --> 00:03:27,280
그리고 나는 텍스트 분석을 위해 깔끔한 데이터 원칙을 사용하는 것을 좋아합니다.

53
00:03:24,480 --> 00:03:32,640
특히 분석의 탐색 단계에서

54
00:03:29,680 --> 00:03:34,879
모델을 만들 때가 되면

55
00:03:32,640 --> 00:03:40,480
종종 기본 수학적 구현이 실제로 필요로 하는 것

56
00:03:38,000 --> 00:03:44,959
일반적으로 다음과 같은 것입니다.

57
00:03:43,040 --> 00:03:52,319
이 특정 표현에 대한 방법을 문서 용어 행렬이라고 합니다.

58
00:03:49,760 --> 00:03:53,840
따라서 정확한 표현은 다음과 다를 수 있습니다.

59
00:03:52,319 --> 00:03:55,760
내가 여기서 보여준 것

60
00:03:53,840 --> 00:03:58,400
내가 여기에 있는 것은 우리가 무게를 다는 것입니다

61
00:03:55,760 --> 00:04:04,720
이 행렬의 각 행이 문서이기 때문에

62
00:04:02,640 --> 00:04:07,439
각 열은 단어입니다.

63
00:04:04,720 --> 00:04:10,080
토큰과 숫자는 다음을 나타냅니다.

64
00:04:07,439 --> 00:04:12,319
각 문서가 몇 번인지 계산합니다.

65
00:04:10,080 --> 00:04:13,519
각 단어를 사용하여 다른 방식으로 가중치를 부여할 수 있습니다.

66
00:04:12,319 --> 00:04:19,359
카운트 대신 TF-IDF 사용

67
00:04:16,720 --> 00:04:20,799
또는 시퀀스 정보를 유지할 수 있습니다.

68
00:04:19,359 --> 00:04:25,199
딥 러닝 모델 구축에 관심이 있지만 기본적으로

69
00:04:23,120 --> 00:04:27,919
모든 종류의 텍스트 모델링

70
00:04:25,199 --> 00:04:30,639
Naive Bayes와 같은 단순한 모델에서

71
00:04:27,919 --> 00:04:33,199
텍스트에 잘 맞는 모델

72
00:04:30,639 --> 00:04:35,680
워드 임베딩까지 정말

73
00:04:33,199 --> 00:04:38,320
최첨단 작업이다.

74
00:04:35,680 --> 00:04:41,120
오늘날 텍스트 데이터의 변환기처럼 발생

75
00:04:39,520 --> 00:04:44,720
우리는 무겁게해야합니다

76
00:04:41,120 --> 00:04:47,280
기능 엔지니어 및 프로세스 언어

77
00:04:44,720 --> 00:04:49,360
어떤 종류의 표현에 그것을 얻을

78
00:04:47,280 --> 00:04:53,680
머신 러닝 알고리즘에 적합

79
00:04:50,960 --> 00:04:56,160
그래서 저는 R의 오픈 소스 프레임워크에서 작업합니다.

80
00:04:54,560 --> 00:05:01,120
Tidymodels라고 하는 모델링 및 머신 러닝과

81
00:04:58,880 --> 00:05:04,800
나는 오늘 Tidymodels 코드를 사용하는 것을 보여줄 것이다.

82
00:05:02,320 --> 00:05:10,639
Tidymodels 프로젝트의 특정 목표 중 일부는

83
00:05:07,360 --> 00:05:13,120
현실을 위한 일관되고 유연한 프레임워크

84
00:05:10,639 --> 00:05:19,199
당신이 알고있는 세계 모델링 실무자 사람들

85
00:05:16,240 --> 00:05:21,360
실제 데이터를 다루는

86
00:05:19,199 --> 00:05:22,800
이제 막 시작하는 사람들

87
00:05:21,360 --> 00:05:27,120
모델링 경험이 풍부한 사람과

88
00:05:24,479 --> 00:05:32,240
목표는 이기종을 조화시키는 것입니다.

89
00:05:28,880 --> 00:05:37,360
R 내에 존재하고 우수한 통계 관행을 장려하기 위한 인터페이스

90
00:05:35,360 --> 00:05:41,360
제가 작업하는 것을 보여드릴 수 있어서 기쁩니다.

91
00:05:38,880 --> 00:05:43,840
빌드 및 텍스트에 적용하는 방법

92
00:05:41,360 --> 00:05:47,120
모델링하지만 많은 이야기를 할 것입니다.

93
00:05:43,840 --> 00:05:50,880
오늘은 Tidymodels에만 국한되지 않습니다.

94
00:05:48,160 --> 00:05:52,800
또는 R에게도. 나는 이것이 R 사용자라는 것을 알고 있습니다.

95
00:05:50,880 --> 00:05:57,440
그룹이지만 우리가 이야기하고 집중할 것은

96
00:05:54,720 --> 00:06:00,479
조금 더 개념적이고 기본적인

97
00:05:57,440 --> 00:06:06,800
기계 학습을 위해 텍스트를 예측자로 변환하는 방법

98
00:06:04,560 --> 00:06:11,280
아직 Tidymodels 및 Tidymodels에 대해 이야기하고 싶지 않다면 흥분됩니다.

99
00:06:08,800 --> 00:06:13,440
이전에 사용한 메타 패키지입니다.

100
00:06:11,280 --> 00:06:16,319
Tidyverse와 유사한 방식으로

101
00:06:13,440 --> 00:06:19,720
메타 패키지이므로 입력한 적이 있다면

102
00:06:16,319 --> 00:06:23,199
라이브러리 Tidyverse를 사용한 다음

103
00:06:19,720 --> 00:06:25,680
시각화를 위한 ggplot2

104
00:06:23,199 --> 00:06:29,680
데이터 조작을 위한 dplyr

105
00:06:25,680 --> 00:06:33,039
Tidymodels도 비슷한 방식으로 작동합니다.

106
00:06:30,560 --> 00:06:36,000
그 안에 다른 패키지가 있습니다

107
00:06:33,039 --> 00:06:39,840
다양한 용도로 사용되는

108
00:06:37,280 --> 00:06:43,440
따라서 전처리 또는 기능

109
00:06:39,840 --> 00:06:48,000
엔지니어링은 보다 광범위한 모델 프로세스의 일부입니다.

110
00:06:45,280 --> 00:06:51,120
프로세스가 실제로 시작된다는 것을 알고 있습니다.

111
00:06:48,000 --> 00:06:54,080
탐색적 데이터 분석으로

112
00:06:52,000 --> 00:06:56,240
어떤 종류의 모델을 결정하는 데 도움이

113
00:06:54,080 --> 00:06:59,280
우리는 구축 할 것입니다 그리고 그것은 온다

114
00:06:56,240 --> 00:07:03,120
내가 생각하는 완성

115
00:06:59,280 --> 00:07:06,479
당신이 할 때 모델 평가

116
00:07:03,120 --> 00:07:09,280
모델이 얼마나 잘 수행되었는지 측정

117
00:07:06,479 --> 00:07:11,919
소프트웨어의 한 조각으로서의 Tidymodels는

118
00:07:09,280 --> 00:07:14,479
각각의 패키지로 구성

119
00:07:11,919 --> 00:07:20,800
우리의 샘플과 같은 특정 초점이 있습니다

120
00:07:17,199 --> 00:07:23,440
데이터를 다시 샘플링하기 위한 것입니다.

121
00:07:20,800 --> 00:07:25,919
부트스트랩 재샘플 생성

122
00:07:23,440 --> 00:07:27,680
교차 검증은 모두 다른 리샘플링

123
00:07:25,919 --> 00:07:31,919
사용할 수 있는 리샘플의 종류

124
00:07:29,520 --> 00:07:34,800
모델 훈련 및 평가

125
00:07:31,919 --> 00:07:38,560
tune 패키지는 하이퍼 매개변수용입니다.

126
00:07:34,800 --> 00:07:40,800
이름에서 짐작할 수 있듯이 튜닝

127
00:07:38,560 --> 00:07:43,520
이 패키지 중 하나는 기능용입니다.

128
00:07:40,800 --> 00:07:45,680
데이터 전처리를 위한 엔지니어링

129
00:07:43,520 --> 00:07:47,120
피쳐 엔지니어링은

130
00:07:45,680 --> 00:07:52,720
레시피라고 하는

131
00:07:49,360 --> 00:07:55,280
그래서 Tidymodels에서 우리는 이 아이디어를

132
00:07:52,720 --> 00:07:57,199
데이터 전처리 및 기능

133
00:07:55,280 --> 00:08:01,199
개념의 공학

134
00:07:57,199 --> 00:08:05,360
선택할 수 있는 단계가 있는 전처리 레시피

135
00:08:03,360 --> 00:08:10,319
성분 또는 변수

136
00:08:07,599 --> 00:08:13,680
사용할 단계를 정의합니다.

137
00:08:11,599 --> 00:08:16,080
그것은 당신의 조리법에 들어갑니다

138
00:08:13,680 --> 00:08:18,319
그런 다음 훈련을 사용하여 준비합니다.

139
00:08:16,080 --> 00:08:21,520
모든 데이터에 적용할 수 있습니다.

140
00:08:18,319 --> 00:08:25,759
테스트 데이터 또는 예측 시점의 새 데이터와 같은 데이터 세트

141
00:08:23,039 --> 00:08:28,319
그래서 우리가

142
00:08:25,759 --> 00:08:30,080
모든 종류의 모델링에 사용

143
00:08:28,319 --> 00:08:34,560
텍스트 데이터를 포함한 모양 및 크기

144
00:08:32,000 --> 00:08:37,919
따라서 일부 기술과 접근 방식은

145
00:08:34,560 --> 00:08:39,200
텍스트 데이터를 사전 처리하는 데 사용하는

146
00:08:37,919 --> 00:08:44,480
다른 종류의 데이터와 동일합니다.

147
00:08:41,519 --> 00:08:46,640
텍스트가 아닌 데이터처럼 사용할 수 있습니다.

148
00:08:44,480 --> 00:08:48,480
숫자 데이터 범주형 데이터 일부

149
00:08:46,640 --> 00:08:51,040
일부는 동일

150
00:08:48,480 --> 00:08:53,040
그러나 당신이 알아야 할 몇 가지

151
00:08:51,040 --> 00:08:58,080
좋은 일을 할 수 있는

152
00:08:55,120 --> 00:09:00,800
이 과정에서 텍스트가 다릅니다.

153
00:08:58,080 --> 00:09:03,680
그리고 무엇의 성격에 따라

154
00:09:00,800 --> 00:09:05,279
언어 데이터는 다음과 같습니다.

155
00:09:03,680 --> 00:09:08,480
그래서 저는 제 책을 썼습니다.

156
00:09:05,279 --> 00:09:11,360
공동 저자 Emile Hvitfeldt 감독

157
00:09:08,480 --> 00:09:14,720
텍스트 분석 및 R을 위한 머신 러닝

158
00:09:11,360 --> 00:09:18,160
그리고 책의 첫 번째 1/3을 완전히

159
00:09:14,720 --> 00:09:20,800
우리가 어떻게 변화하는지에 중점을 둡니다.

160
00:09:18,160 --> 00:09:23,600
우리가 가지고 있는 자연어

161
00:09:20,800 --> 00:09:25,920
모델링을 위한 피쳐로 텍스트 데이터

162
00:09:23,600 --> 00:09:28,800
중간 섹션은 우리가 사용하는 방법에 관한 것입니다

163
00:09:25,920 --> 00:09:30,800
이러한 기능은

164
00:09:28,800 --> 00:09:33,360
더 간단하거나 더 전통적인 기계

165
00:09:30,800 --> 00:09:35,839
정규화와 같은 학습 모델

166
00:09:33,360 --> 00:09:40,240
회귀 또는 지원 벡터 기계 및

167
00:09:37,360 --> 00:09:42,800
그런 다음 책의 마지막 3분의 1

168
00:09:40,240 --> 00:09:46,000
우리가 딥 러닝을 사용하는 방법에 대해 이야기합니다.

169
00:09:42,800 --> 00:09:48,640
텍스트 데이터가 있는 모델로 딥 러닝

170
00:09:46,000 --> 00:09:51,279
모델은 여전히 이러한 종류의

171
00:09:48,640 --> 00:09:54,480
자연어에서 변형

172
00:09:51,279 --> 00:10:01,600
이러한 종류의 모델에 대한 입력으로 기능에

173
00:09:58,880 --> 00:10:05,920
딥 러닝 모델은 종종

174
00:10:03,040 --> 00:10:07,920
본질적으로 기능의 구조를 학습

175
00:10:05,920 --> 00:10:10,240
텍스트에서

176
00:10:07,920 --> 00:10:12,800
더 전통적이거나 더 단순한 기계

177
00:10:10,240 --> 00:10:15,279
학습 모델은

178
00:10:12,800 --> 00:10:17,440
그래서 이 책은 이제 완성되었고

179
00:10:15,279 --> 00:10:20,560
이달부터 11월까지 가능

180
00:10:18,480 --> 00:10:23,600
사람들은 첫 번째 종이를 얻습니다.

181
00:10:20,560 --> 00:10:26,320
사본 및 또한 이 책은 유효합니다

182
00:10:23,600 --> 00:10:30,720
smalltar.com에서 전체

183
00:10:28,560 --> 00:10:33,519
따라서 텍스트를 처음 다루는 경우

184
00:10:30,720 --> 00:10:35,760
이를 이해하는 데이터

185
00:10:33,519 --> 00:10:38,720
기본적인 전처리 접근법

186
00:10:35,760 --> 00:10:41,760
텍스트가 가능하도록 설정합니다.

187
00:10:38,720 --> 00:10:43,839
효과적인 모델을 훈련하기 위해

188
00:10:41,760 --> 00:10:45,200
당신이 정말로 텍스트에 경험이 있다면

189
00:10:43,839 --> 00:10:47,680
데이터를 많이 다루었다면

190
00:10:45,200 --> 00:10:51,360
이미 당신은 아마 우리처럼

191
00:10:48,959 --> 00:10:58,000
기존 리소스 또는 문헌을 알고 있는지 여부

192
00:10:54,480 --> 00:11:01,680
그것은 책이나 튜토리얼 또는 블로그 게시물입니다.

193
00:10:58,000 --> 00:11:05,279
에 관해서는 매우 희박하다.

194
00:11:02,880 --> 00:11:07,600
방법에 대한 자세한 사려 깊은 탐구

195
00:11:05,279 --> 00:11:11,120
이러한 전처리 단계가 작동합니다.

196
00:11:07,600 --> 00:11:14,000
이 기능에서 선택한 방법

197
00:11:11,120 --> 00:11:17,519
엔지니어링 단계는 모델 출력에 영향을 미칩니다.

198
00:11:15,600 --> 00:11:20,000
그래서 통과하자

199
00:11:17,519 --> 00:11:23,360
이 중 몇 가지는 기본과 같은

200
00:11:21,360 --> 00:11:25,440
피쳐 엔지니어링 접근 방식 및 방법

201
00:11:23,360 --> 00:11:28,800
그들은 일하고 그들이하는 일부터 시작하겠습니다.

202
00:11:27,040 --> 00:11:31,920
토큰화

203
00:11:28,800 --> 00:11:33,839
따라서 일반적으로

204
00:11:31,920 --> 00:11:36,800
자연에서 정보를 전송

205
00:11:33,839 --> 00:11:40,480
언어 대 기계 학습 기능

206
00:11:38,320 --> 00:11:44,480
정말 모든 종류의 텍스트 분석

207
00:11:40,480 --> 00:11:47,040
탐색적 데이터 분석 포함

208
00:11:44,480 --> 00:11:52,320
또는 모델을 구축합니다. 뭐든지 토큰화

209
00:11:49,040 --> 00:11:55,360
토큰화에서 우리는 입력을 받습니다.

210
00:11:52,320 --> 00:11:57,120
문자열 일부 문자 벡터 및 일부

211
00:11:55,360 --> 00:11:59,440
토큰 유형의 종류

212
00:11:57,120 --> 00:12:02,079
의미 있는 텍스트 단위

213
00:11:59,440 --> 00:12:05,600
우리는 단어에 관심이 있습니다

214
00:12:02,079 --> 00:12:07,680
그리고 우리는 입력 조각을

215
00:12:05,600 --> 00:12:09,519
유형에 해당하는 토큰

216
00:12:07,680 --> 00:12:12,480
우리는 관심이있다

217
00:12:09,519 --> 00:12:15,120
가장 일반적으로 의미 있는 단위 또는

218
00:12:12,480 --> 00:12:17,839
텍스트를 분할하려는 토큰 유형

219
00:12:15,120 --> 00:12:19,040
의 단위로 단어는

220
00:12:17,839 --> 00:12:21,440
그래서 이것은 보일 수 있습니다

221
00:12:19,040 --> 00:12:24,480
직설적이거나 명백하지만

222
00:12:21,440 --> 00:12:28,160
명확하게 정의하기 어렵다

223
00:12:24,480 --> 00:12:30,880
많은 또는 대부분의 언어에 대한 단어는 무엇입니까

224
00:12:29,519 --> 00:12:35,839
많은 언어가 공백을 사용하지 않습니다

225
00:12:34,000 --> 00:12:38,240
단어 사이에 전혀

226
00:12:35,839 --> 00:12:40,959
도전을 제시하는

227
00:12:38,240 --> 00:12:44,480
토큰화를 위해

228
00:12:40,959 --> 00:12:48,160
영어와 한국어와 같은 공백을 사용하십시오

229
00:12:45,519 --> 00:12:53,120
종종 모호한 특정 예가 있습니다.

230
00:12:49,839 --> 00:12:55,040
영어로 된 수축처럼 like don't

231
00:12:53,120 --> 00:12:56,800
어느 것이어야

232
00:12:55,040 --> 00:12:59,200
당신은 아마 더 정확하게 알고

233
00:12:56,800 --> 00:13:01,519
두 단어를 방법으로 간주

234
00:12:59,200 --> 00:13:04,079
입자는 한국어로 사용됩니다.

235
00:13:01,519 --> 00:13:06,240
대명사와 부정 단어가 어떻게

236
00:13:04,079 --> 00:13:08,000
같은 로맨스 언어로 작성

237
00:13:06,240 --> 00:13:09,920
그들이 갇혀있는 이탈리아어와 프랑스어

238
00:13:08,000 --> 00:13:12,399
함께 그리고 정말로 아마도 그들은 그래야만 할 것입니다

239
00:13:09,920 --> 00:13:13,839
두 단어로 간주

240
00:13:12,399 --> 00:13:15,519
당신이 무엇인지 파악한 후에

241
00:13:13,839 --> 00:13:17,839
할 것이고 당신은 몇 가지 선택을 할 것입니다

242
00:13:15,519 --> 00:13:20,480
텍스트를 토큰화하면 켜집니다.

243
00:13:17,839 --> 00:13:23,839
사용할 수 있는 방법

244
00:13:20,480 --> 00:13:26,880
탐색적 데이터 분석에서 또는

245
00:13:23,839 --> 00:13:28,399
감독되지 않은 알고리즘 또는 기능

246
00:13:26,880 --> 00:13:30,320
예측 모델링을 위해

247
00:13:28,399 --> 00:13:32,720
우리는 여기서 그리고 이것들이 무엇인지에 대해 이야기하고 있습니다

248
00:13:30,320 --> 00:13:35,200
결과가 여기에 표시되므로 이러한 결과는

249
00:13:32,720 --> 00:13:38,000
에 대해 학습된 회귀 모델에서

250
00:13:35,200 --> 00:13:40,639
미디어에 대한 설명

251
00:13:38,000 --> 00:13:45,199
영국 테이트 컬렉션의 아트웍에서

252
00:13:43,279 --> 00:13:47,680
우리가 무엇을 예측하고 있는지

253
00:13:45,199 --> 00:13:52,320
예측은 몇 년

254
00:13:48,880 --> 00:13:56,320
를 기반으로 만들어진 예술 작품이었습니다.

255
00:13:53,120 --> 00:13:58,560
작품이 만들어진 매체

256
00:13:56,320 --> 00:14:00,079
와 매체는 다음과 같이 설명됩니다.

257
00:13:58,560 --> 00:14:02,079
약간의 텍스트

258
00:14:00,079 --> 00:14:07,440
그래파이트를 사용하여 만든 작품을 여기서 볼 수 있습니다.

259
00:14:04,079 --> 00:14:09,279
수채화와 조각이 더 가능성이 높았습니다.

260
00:14:07,440 --> 00:14:10,959
더 일찍 생성될

261
00:14:09,279 --> 00:14:13,360
그것이 올 가능성이 더 높더라도

262
00:14:10,959 --> 00:14:17,839
사용하여 만든 오래된 예술 및 예술 작품에서

263
00:14:15,360 --> 00:14:22,880
사진 화면 포인트 또는 미안 화면 인쇄

264
00:14:20,639 --> 00:14:27,760
스크린 인쇄와 똥

265
00:14:24,720 --> 00:14:29,920
반짝이는 가능성이 더 높습니다.

266
00:14:27,760 --> 00:14:32,560
나중에 생성됨. 거기에 이것은 더 가능성이 있습니다

267
00:14:29,920 --> 00:14:37,519
현대 미술에서 오는 현대 미술

268
00:14:33,440 --> 00:14:41,519
이 텍스트를 토큰화하는 방법

269
00:14:39,440 --> 00:14:43,839
당신은 우리가 자연적인 인간으로 시작했다는 것을 알고 있습니다

270
00:14:41,519 --> 00:14:47,519
작성하는 사람들의 생성된 텍스트

271
00:14:43,839 --> 00:14:49,760
언론에 대한 설명

272
00:14:47,519 --> 00:14:53,120
이 예술 작품은

273
00:14:50,959 --> 00:14:55,440
그리고 우리가 그 자연스러운 것을 토큰화한 방법

274
00:14:53,120 --> 00:14:57,760
우리가 시작한 인간 생성 텍스트

275
00:14:55,440 --> 00:14:59,839
우리가 배운 것에 큰 영향을 미칩니다

276
00:14:57,760 --> 00:15:01,839
다른 방식으로 토큰화하면

277
00:15:00,720 --> 00:15:04,880
우리는 달라졌을 것이다

278
00:15:01,839 --> 00:15:07,760
결과는 다음과 같은 성능 측면에서

279
00:15:05,839 --> 00:15:10,320
정확하게 예측할 수 있었습니다

280
00:15:07,760 --> 00:15:12,240
연도를 예측하고

281
00:15:10,320 --> 00:15:15,279
모델을 어떻게 해석하는지

282
00:15:12,240 --> 00:15:17,279
우리가 그것으로부터 배울 수 있다는 것

283
00:15:15,279 --> 00:15:19,760
이것은 토큰화의 한 종류입니다.

284
00:15:17,279 --> 00:15:21,760
한 단어지만 우리도

285
00:15:19,760 --> 00:15:24,000
대신 토큰화하는 다른 방법

286
00:15:21,760 --> 00:15:27,440
한 단어로 분해하거나

287
00:15:24,000 --> 00:15:31,279
n-gram으로 토큰화할 수 있는 유니그램

288
00:15:27,440 --> 00:15:35,199
따라서 n-gram은 다음의 연속 시퀀스입니다.

289
00:15:31,279 --> 00:15:37,920
주어진 텍스트 시퀀스의 N개 항목

290
00:15:35,199 --> 00:15:41,680
그래서 이것은 같은 작은 조각을 보여줍니다

291
00:15:37,920 --> 00:15:44,880
이 동물을 설명하는 텍스트의 비트

292
00:15:41,680 --> 00:15:47,440
bi-gram 또는 n-gram으로 나눈다.

293
00:15:44,880 --> 00:15:49,360
두 개의 토큰이 있으므로 단어가 어떻게

294
00:15:47,440 --> 00:15:54,959
bi-gram이 겹쳐서 단어 collard

295
00:15:51,519 --> 00:15:58,480
첫 번째 bigrams 모두에 나타납니다.

296
00:15:56,000 --> 00:16:00,800
칼라 페 케리 페 케리도

297
00:15:58,480 --> 00:16:03,920
그래서 n-그램으로 참조

298
00:16:00,800 --> 00:16:07,040
토큰화는 텍스트를 따라 슬라이드하여

299
00:16:03,920 --> 00:16:11,120
겹치는 토큰 세트 생성

300
00:16:07,040 --> 00:16:14,480
이것은 같은 것에 대한 트라이 그램을 보여줍니다.

301
00:16:11,120 --> 00:16:17,680
따라서 유니그램을 사용하는 한 단어는

302
00:16:14,480 --> 00:16:20,560
더 빠르고 효율적이지만

303
00:16:17,680 --> 00:16:23,360
단어 순서에 대한 정보 캡처

304
00:16:20,560 --> 00:16:25,839
더 높은 값을 사용하고 있습니다.

305
00:16:23,360 --> 00:16:30,320
둘, 셋 또는 그 이상 유지

306
00:16:28,160 --> 00:16:32,240
단어에 대한 더 복잡한 정보

307
00:16:30,320 --> 00:16:36,160
순서와 개념

308
00:16:33,120 --> 00:16:41,440
여러 단어로 된 구문으로 설명된

309
00:16:37,680 --> 00:16:43,839
그러나 토큰의 벡터 공간

310
00:16:41,440 --> 00:16:47,199
극적으로 증가

311
00:16:43,839 --> 00:16:50,480
이는 토큰 감소에 해당합니다.

312
00:16:47,199 --> 00:16:52,880
우리는 각 토큰을 그다지 세지 않습니다

313
00:16:50,480 --> 00:16:55,120
여러 번 그리고 그 의미에 따라

314
00:16:52,880 --> 00:16:56,480
귀하의 특정 데이터 세트

315
00:16:55,120 --> 00:17:00,399
좋은 결과를 얻지 못할 수도 있습니다

316
00:16:58,160 --> 00:17:03,519
서로 다른 정도를 결합하여

317
00:17:00,399 --> 00:17:06,400
n-grams를 사용하면 다음을 추출할 수 있습니다.

318
00:17:03,519 --> 00:17:09,679
텍스트와 다른 수준의 세부 정보를 제공하므로 유니그램

319
00:17:07,760 --> 00:17:11,439
어떤 개별 단어가 있는지 말할 수 있습니다

320
00:17:09,679 --> 00:17:14,079
많이 사용되었다

321
00:17:11,439 --> 00:17:18,319
그 단어 중 일부는 간과 될 수 있습니다

322
00:17:15,760 --> 00:17:19,919
바이그램 또는 트라이그램 크라운의 경우

323
00:17:18,319 --> 00:17:23,360
자주 다른 단어와 함께 나타나지 마십시오

324
00:17:23,520 --> 00:17:28,960
이 플롯은 에 대한 모델 성능을 비교합니다.

325
00:17:26,720 --> 00:17:32,080
예측하는 올가미 회귀 모델

326
00:17:28,960 --> 00:17:34,640
대법원 판결의 해

327
00:17:32,080 --> 00:17:37,840
미국 대법원의 의견

328
00:17:34,640 --> 00:17:39,679
세 가지 다른 정도의 n-gram

329
00:17:37,840 --> 00:17:42,880
우리가 여기서 하는 것은 우리가 취하고 있는 것입니다

330
00:17:39,679 --> 00:17:44,240
United의 글의 텍스트

331
00:17:42,880 --> 00:17:49,760
주 대법원과 우리는 예측하고 있습니다

332
00:17:47,120 --> 00:17:51,840
언제 했어 그 문자가 언제였더라

333
00:17:49,760 --> 00:17:54,080
우리가 몇 살인지 예측할 수 있도록 작성되었습니다

334
00:17:51,840 --> 00:17:58,799
텍스트의 일부는 텍스트의 내용에서 가져온 것입니다.

335
00:17:55,360 --> 00:18:01,840
그래서 토큰의 수를 유지

336
00:17:58,799 --> 00:18:08,080
유니그램만 사용하여 1000에서 상수

337
00:18:04,480 --> 00:18:10,160
이 코퍼스에 대해 가장 잘 수행됩니다.

338
00:18:08,080 --> 00:18:13,600
미국 대법원의 의견

339
00:18:11,280 --> 00:18:16,240
에 따라 항상 그런 것은 아닙니다.

340
00:18:13,600 --> 00:18:18,799
데이터 세트를 사용하는 모델의 종류

341
00:18:16,240 --> 00:18:21,679
그 자체로 우리는 최고의 성능을 볼 수 있습니다

342
00:18:18,799 --> 00:18:22,640
유니 그램과 바이 그램을 결합하거나 아마도

343
00:18:21,679 --> 00:18:25,760
다른 옵션

344
00:18:23,679 --> 00:18:28,720
이 경우 통합하려는 경우

345
00:18:25,760 --> 00:18:30,480
좀 더 복잡한 정보

346
00:18:28,720 --> 00:18:34,000
우리는 바이그램과

347
00:18:30,480 --> 00:18:36,799
아마도 우리가 필요로 할 트라이그램

348
00:18:34,000 --> 00:18:40,160
수를 늘리다

349
00:18:36,799 --> 00:18:43,039
모델의 토큰

350
00:18:40,160 --> 00:18:46,000
따라서 결과를 볼 때 염두에 두십시오.

351
00:18:43,039 --> 00:18:48,960
이와 같이 n-gram을 식별하는 것은

352
00:18:46,000 --> 00:18:51,039
계산적으로 비싸다

353
00:18:48,960 --> 00:18:54,640
이것은 특히 비교된다

354
00:18:51,760 --> 00:18:57,600
모델과 같은 양의 개선

355
00:18:54,640 --> 00:19:00,640
우리가 자주 보는 모델 성능에서

356
00:18:58,720 --> 00:19:03,600
우리가 겸손한 것을 알고 있다면

357
00:19:00,640 --> 00:19:05,760
빅그램을 추가하여 개선합니다.

358
00:19:03,600 --> 00:19:08,640
얼마나 많은지 기억하는 것이 중요합니다.

359
00:19:05,760 --> 00:19:11,039
우리가 비교하는 개선 사항

360
00:19:08,640 --> 00:19:13,200
얼마나 걸립니까

361
00:19:11,039 --> 00:19:15,840
바이그램을 식별한 다음 훈련

362
00:19:13,200 --> 00:19:18,480
예를 들어 이 데이터 세트에 대한 모델

363
00:19:15,840 --> 00:19:20,799
우리가 개최한 대법원의 의견

364
00:19:18,480 --> 00:19:24,480
토큰의 수는 일정하므로

365
00:19:20,799 --> 00:19:27,120
모델 훈련에는 동일한 수의 토큰이 있습니다.

366
00:19:25,919 --> 00:19:35,200
바이그램과 유니그램을 함께 사용하면 훈련 시간이 두 배 더 걸립니다.

367
00:19:33,280 --> 00:19:38,240
기능 엔지니어링을 수행하고

368
00:19:35,200 --> 00:19:42,000
유니그램 뿐만 아니라 훈련 및 추가

369
00:19:38,240 --> 00:19:44,320
트라이 그램에서도 거의 5가 걸립니다.

370
00:19:42,000 --> 00:19:46,799
유니그램 교육만큼

371
00:19:44,320 --> 00:19:50,640
혼자이므로 이것은 계산적으로

372
00:19:46,799 --> 00:19:50,640
값비싼 일

373
00:19:51,760 --> 00:19:56,559
다른 방향으로 가고

374
00:19:53,760 --> 00:19:58,960
보다 작은 단위로 토큰화할 수 있습니다.

375
00:19:56,559 --> 00:20:00,880
이와 같은 말을 라고 한다.

376
00:19:58,960 --> 00:20:05,440
캐릭터 대상 포진 그래서 우리는 단어를

377
00:20:03,280 --> 00:20:08,480
칼라 페커리

378
00:20:05,440 --> 00:20:10,880
단어를 보는 대신

379
00:20:08,480 --> 00:20:13,120
우리는 내려가서 하위 단어를 볼 수 있습니다

380
00:20:10,880 --> 00:20:16,000
정보는 여러 가지가 있습니다

381
00:20:13,120 --> 00:20:17,440
단어를 하위 단어로 나누는 방법

382
00:20:16,000 --> 00:20:20,880
머신러닝에 적합한

383
00:20:18,480 --> 00:20:23,440
그리고 종종 이러한 종류의 접근 방식

384
00:20:20,880 --> 00:20:25,200
또는 알고리즘은 다음과 같은 이점이 있습니다.

385
00:20:23,440 --> 00:20:31,360
알려지지 않은 단어나 새로운 단어를 인코딩할 수 있음

386
00:20:29,039 --> 00:20:33,760
예측 시간에 그래서 언제 그것이 될 때

387
00:20:31,360 --> 00:20:36,400
새로운 데이터에 대한 예측 시간

388
00:20:33,760 --> 00:20:39,200
드문 일이 아닙니다.

389
00:20:36,400 --> 00:20:41,200
그 당시의 새로운 어휘가 되고

390
00:20:39,200 --> 00:20:42,640
훈련에서 그들을 보지 못했다면

391
00:20:41,200 --> 00:20:45,600
우리가 무엇을 할 것인지 알고 있는 데이터

392
00:20:42,640 --> 00:20:49,360
우리가 훈련할 때 그 새로운 단어에 대해

393
00:20:45,600 --> 00:20:52,000
하위 단어 정보를 자주 사용하여

394
00:20:49,360 --> 00:20:54,960
하위 단어를 본 경우 새 단어를 처리하십시오.

395
00:20:52,880 --> 00:20:58,400
훈련 데이터 세트에서

396
00:20:55,760 --> 00:21:01,440
이러한 종류의 하위 단어 정보를 사용하여

397
00:20:58,400 --> 00:21:04,720
형태소를 통합하는 방법이다

398
00:21:01,440 --> 00:21:06,240
당신이 알고 있는 우리의 모델에 시퀀스

399
00:21:04,720 --> 00:21:09,280
이것의 다양한 종류에 적용되는 것입니다

400
00:21:08,080 --> 00:21:13,360
영어뿐만 아니라 다양한 언어

401
00:21:11,919 --> 00:21:16,240
따라서 이 결과는

402
00:21:13,360 --> 00:21:20,000
데이터 세트가 있는 분류 모델

403
00:21:16,240 --> 00:21:22,960
매우 짧은 텍스트는 이름일 뿐입니다.

404
00:21:20,000 --> 00:21:27,120
미국의 우체국은 너무 짧습니다.

405
00:21:24,240 --> 00:21:28,799
모델의 목표는

406
00:21:27,120 --> 00:21:35,280
하와이에 위치한 우체국

407
00:21:32,880 --> 00:21:37,280
태평양 한가운데 또는

408
00:21:35,280 --> 00:21:41,360
그것은 미국의 나머지 부분에 위치

409
00:21:38,159 --> 00:21:46,480
그래서 모델에 대한 기능을 만들었습니다.

410
00:21:42,159 --> 00:21:49,200
이 우체국 이름의 하위 단어

411
00:21:46,480 --> 00:21:53,120
그리고 우리는 이름이

412
00:21:49,200 --> 00:21:57,440
h와 p로 시작하거나 에일을 포함하는

413
00:21:54,240 --> 00:22:00,240
하위 단어는 하와이에 있을 가능성이 더 높습니다.

414
00:21:57,440 --> 00:22:06,480
하위 단어 a 및 d 및 ri 및 ing은 다음과 같습니다.

415
00:22:04,559 --> 00:22:09,360
우체국에서 올 확률이 더 높습니다.

416
00:22:06,480 --> 00:22:11,440
하와이 밖에 있는

417
00:22:09,360 --> 00:22:14,480
이것은 우리가

418
00:22:11,440 --> 00:22:17,280
다르게 토큰화하고 우리는

419
00:22:14,480 --> 00:22:19,600
새로운 것을 배우다 우리는 무언가를 배울 수 있다

420
00:22:18,559 --> 00:22:24,320
Tidymodels에서 우리는 이 모든 것을 수집합니다.

421
00:22:21,840 --> 00:22:26,880
토큰화에 대한 결정의 종류

422
00:22:24,320 --> 00:22:29,919
그리고 다음과 같은 코드

423
00:22:26,880 --> 00:22:33,760
그래서 우리는 무엇을 지정하는 조리법으로 시작합니다

424
00:22:30,799 --> 00:22:35,679
우리가 사용할 변수 또는 성분

425
00:22:33,760 --> 00:22:38,640
그런 다음 이러한 전처리를 정의합니다.

426
00:22:35,679 --> 00:22:41,600
처음에는 이렇게 단계를 밟아도

427
00:22:38,640 --> 00:22:44,159
그리고 틀림없이 당신은 간단하고 기본적인 것을 알고 있습니다

428
00:22:41,600 --> 00:22:47,120
우리가 내리는 선택이 우리의

429
00:22:44,159 --> 00:22:50,400
모델링 결과를 크게

430
00:22:47,120 --> 00:22:52,080
다음 전처리 um 단계

431
00:22:50,400 --> 00:22:56,240
내가 말하고 싶은 것은 스톱 워드

432
00:22:53,600 --> 00:23:00,320
그래서 일단 텍스트를 분할하면

433
00:22:56,240 --> 00:23:03,360
토큰으로 우리는 종종 그렇지 않다는 것을 발견합니다

434
00:23:00,320 --> 00:23:06,720
모든 단어는 같은 양의

435
00:23:03,360 --> 00:23:09,520
정보

436
00:23:06,720 --> 00:23:11,840
모두 실제로 기계 학습 작업을 위해

437
00:23:09,520 --> 00:23:13,919
거의 또는

438
00:23:11,840 --> 00:23:16,080
의미 있는 정보가 없을 수도 있습니다

439
00:23:13,919 --> 00:23:18,880
불용어

440
00:23:16,080 --> 00:23:20,400
그래서 이것은 불용어 목록 중 하나입니다

441
00:23:18,880 --> 00:23:22,720
사용할 수 있는

442
00:23:20,400 --> 00:23:28,000
한국어이므로 일반적인 조언과 관행입니다.

443
00:23:24,960 --> 00:23:31,200
그냥 제거하기만 하면 제거

444
00:23:28,000 --> 00:23:35,039
많은 경우 이러한 불용어를 제거하십시오.

445
00:23:31,919 --> 00:23:36,640
자연어 처리 작업

446
00:23:35,039 --> 00:23:39,600
내가 여기서 보여주는 것

447
00:23:36,640 --> 00:23:41,919
더 짧은 것 중 하나의 전체입니다.

448
00:23:39,600 --> 00:23:44,320
사용되는 영어 불용어 목록

449
00:23:41,919 --> 00:23:52,080
정말 광범위하게 나와 같은 단어라는 것을 알 수 있습니다.

450
00:23:47,200 --> 00:23:54,400
me 내 대명사 접속사 및 of

451
00:23:52,080 --> 00:23:57,679
그리고 이것은 매우 일반적인 단어입니다

452
00:23:54,400 --> 00:24:00,400
매우 중요하다고 여겨지지 않는

453
00:23:57,679 --> 00:24:04,400
그냥 제거하기로 결정

454
00:24:00,400 --> 00:24:07,279
불용어는 종종 더 많이 관련되고

455
00:24:04,400 --> 00:24:08,960
아마도 당신이 생각하는 것보다

456
00:24:07,279 --> 00:24:12,000
많이 반영된 것보다

457
00:24:08,960 --> 00:24:15,840
거기에 있는 자원의

458
00:24:12,000 --> 00:24:18,880
그래서 거의 항상 현실 세계 NLP

459
00:24:15,840 --> 00:24:22,400
실무자는 미리 만들어진 불용어 목록을 사용합니다.

460
00:24:20,000 --> 00:24:26,400
그래서 이 플롯은

461
00:24:22,400 --> 00:24:28,720
세 가지 공통에 대한 교차점 설정

462
00:24:26,400 --> 00:24:31,200
영어로 된 불용어 목록

463
00:24:28,720 --> 00:24:32,960
화난 음모라고 불리는 것에서

464
00:24:31,200 --> 00:24:37,440
따라서 세 개의 목록을

465
00:24:32,960 --> 00:24:40,159
눈덩이 목록 스마트 및 ISO 목록

466
00:24:37,440 --> 00:24:41,840
그래서 당신은 길이를 볼 수 있습니다

467
00:24:40,159 --> 00:24:43,679
목록은 길이로 표시됩니다.

468
00:24:41,840 --> 00:24:46,400
막대 그리고 우리는 본다

469
00:24:43,679 --> 00:24:48,799
단어가 공통되는 교차점

470
00:24:46,400 --> 00:24:51,760
이 목록에서 수직으로

471
00:24:48,799 --> 00:24:55,760
막대가 있으므로 목록의 길이가 상당히 다릅니다.

472
00:24:52,960 --> 00:24:58,320
또한 모든 항목이

473
00:24:55,760 --> 00:25:00,720
같은 단어 집합

474
00:24:58,320 --> 00:25:03,120
기억해야 할 중요한 것

475
00:25:00,720 --> 00:25:06,880
불용어 사전은

476
00:25:04,240 --> 00:25:10,000
그들은 일부에서 생성되지 않습니다

477
00:25:06,880 --> 00:25:16,080
중립적인 완벽한 설정이지만 대신

478
00:25:12,799 --> 00:25:20,480
그들은 상황에 따라 다릅니다

479
00:25:16,960 --> 00:25:23,600
그들은 이 두 가지 모두에 편향될 수 있습니다.

480
00:25:20,480 --> 00:25:27,039
그것들은 목록이기 때문에 사실입니다.

481
00:25:23,600 --> 00:25:28,559
대규모 언어 데이터 세트에서 생성

482
00:25:27,039 --> 00:25:32,159
사용된 데이터의 특성을 반영합니다.

483
00:25:30,640 --> 00:25:37,440
그들의 창조는 이것이다.

484
00:25:34,000 --> 00:25:40,559
영어로 된 10개의 단어

485
00:25:37,440 --> 00:25:43,039
언어 스마트 사전에는 없지만

486
00:25:40,559 --> 00:25:45,600
영어 눈덩이 사전

487
00:25:43,039 --> 00:25:47,520
그래서 그것들이 모두 수축이라는 것을 알아차리세요.

488
00:25:45,600 --> 00:25:50,000
하지만 그건 눈덩이 때문이 아니야

489
00:25:47,520 --> 00:25:52,240
교환은 수축을 포함하지 않습니다

490
00:25:50,000 --> 00:25:56,960
많은 사람들이

491
00:25:55,440 --> 00:26:01,360
그녀가 이 목록에 있다는 것은

492
00:25:58,960 --> 00:26:03,360
그 목록에는 그가 있지만 그것은 없다

493
00:26:01,360 --> 00:26:05,600
그녀의 목록

494
00:26:03,360 --> 00:26:07,679
그래서 이것은 그 예입니다

495
00:26:05,600 --> 00:26:11,440
내가 언급한 편향은 다음과 같은 이유로 발생합니다.

496
00:26:07,679 --> 00:26:13,520
이 목록은 대용량 데이터에서 생성됩니다.

497
00:26:11,440 --> 00:26:19,760
텍스트 사전 제작자가 가장 많이 보는 세트

498
00:26:16,400 --> 00:26:22,480
어떤 큰 말뭉치에서 자주 사용되는 단어

499
00:26:19,760 --> 00:26:24,720
그들이 끊는 언어

500
00:26:22,480 --> 00:26:28,400
그런 다음 무엇을 포함할지 또는

501
00:26:26,080 --> 00:26:29,919
당신이 알고 제외

502
00:26:28,400 --> 00:26:33,840
그들이 작성한 목록을 기반으로

503
00:26:29,919 --> 00:26:36,799
가지고 있고 당신은 여기에서 끝납니다. 왜냐하면

504
00:26:33,840 --> 00:26:39,760
많은 대규모 언어 데이터 세트에서

505
00:26:36,799 --> 00:26:45,679
당신은 더 많은 표현을 가지고 있습니다

506
00:26:42,720 --> 00:26:47,440
당신이 끝내는 남자들

507
00:26:45,679 --> 00:26:51,840
이 같은 상황에서 stopword

508
00:26:47,440 --> 00:26:54,799
목록에는 그가 있지만 그녀는 없습니다

509
00:26:51,840 --> 00:26:57,840
많은 결정을 내릴 때

510
00:26:54,799 --> 00:27:01,120
언어로 모델링 또는 분석

511
00:26:57,840 --> 00:27:03,919
실무자로서 우리는 결정해야합니다

512
00:27:01,120 --> 00:27:07,679
특정 도메인에 적합한 것

513
00:27:05,279 --> 00:27:10,720
이것이 사실일 때도 사실로 밝혀졌습니다

514
00:27:07,679 --> 00:27:12,960
불용어 목록을 선택하기 위해 온다

515
00:27:10,720 --> 00:27:14,720
그래서 Tidymodels에서 우리는

516
00:27:12,960 --> 00:27:19,200
불용어 제거와 같은 전처리 단계

517
00:27:17,120 --> 00:27:21,760
추가 단계를 추가하여

518
00:27:19,200 --> 00:27:24,720
조리법 그래서 먼저 우리는 무엇을 지정

519
00:27:21,760 --> 00:27:28,000
우리가 사용할 변수를 토큰화했습니다.

520
00:27:24,720 --> 00:27:30,720
텍스트 및 이제 우리는 제거하고 있습니다

521
00:27:28,000 --> 00:27:32,640
기본값만 사용하는 불용어

522
00:27:30,720 --> 00:27:35,360
우리는 어떤 단계도 통과하지 않기 때문에

523
00:27:32,640 --> 00:27:37,600
우리가 할 수 있는 다른 주장

524
00:27:35,360 --> 00:27:39,919
기본이 아닌 단계 또는 사용자 정의를 사용하십시오.

525
00:27:37,600 --> 00:27:42,399
그것이 우리 도메인에 가장 적절한지 나열하십시오.

526
00:27:42,880 --> 00:27:48,960
이 플롯은 모델 성능을 비교합니다.

527
00:27:46,799 --> 00:27:52,399
년을 예측하기 위해

528
00:27:50,159 --> 00:27:55,039
동일한 데이터 세트

529
00:27:52,399 --> 00:27:58,240
3명의 대법원 의견

530
00:27:55,039 --> 00:28:02,080
다른 길이의 다른 불용어 사전

531
00:27:59,279 --> 00:28:04,480
따라서 눈덩이 사전에는

532
00:28:02,080 --> 00:28:06,960
가장 적은 수의 단어와 이것에서

533
00:28:04,480 --> 00:28:10,320
최상의 성능을 내는 경우

534
00:28:06,960 --> 00:28:12,799
따라서 더 적은 수의 불용어를 제거하면

535
00:28:10,320 --> 00:28:16,399
여기 최고의 성능 그래서 이것은

536
00:28:12,799 --> 00:28:19,440
특정 결과를 일반화할 수 없음

537
00:28:16,399 --> 00:28:22,080
사실을 제외한 모든 데이터 세트와 컨텍스트

538
00:28:19,440 --> 00:28:23,919
다른 세트를 제거하는

539
00:28:22,080 --> 00:28:26,799
불용어는 눈에 띄게 다를 수 있습니다

540
00:28:23,919 --> 00:28:29,919
모델에 미치는 영향은 상당히

541
00:28:26,799 --> 00:28:33,200
양도 가능하므로 알 수 있는 유일한 방법

542
00:28:29,919 --> 00:28:35,360
가장 좋은 것은 시도하는 것입니다

543
00:28:33,200 --> 00:28:37,600
몇 가지 옵션과 기계 참조

544
00:28:35,360 --> 00:28:41,360
일반적으로 학습.

545
00:28:39,279 --> 00:28:42,480
이것은 우리와 같은 경험적 분야입니다.

546
00:28:41,360 --> 00:28:47,440
우리는 종종 사전에 이유가 없다는 것을 모릅니다

547
00:28:45,679 --> 00:28:49,919
가장 좋은 일이 무엇인지 알고

548
00:28:47,440 --> 00:28:52,240
그래서 일반적으로 우리는

549
00:28:49,919 --> 00:28:54,960
다른 옵션을 시도하여

550
00:28:52,240 --> 00:29:01,039
최고가 되십시오. 그 다음 세 번째

551
00:28:58,799 --> 00:29:04,000
내가 말하고 싶은 전처리 단계

552
00:29:02,080 --> 00:29:07,760
텍스트가 형태소 분석 중이기 때문에

553
00:29:05,279 --> 00:29:10,640
그래서 우리가 텍스트를 자주 다룰 때

554
00:29:07,760 --> 00:29:14,399
문서에는 다른 버전의

555
00:29:10,640 --> 00:29:18,559
하나의 기본 단어는 종종 어간이라고 합니다.

556
00:29:15,440 --> 00:29:20,000
영어로 예를 들면

557
00:29:18,559 --> 00:29:22,000
차이에 관심이 없다면

558
00:29:20,000 --> 00:29:26,480
복수와 동물 사이

559
00:29:24,480 --> 00:29:31,279
특이하고 우리는 둘 다 함께 치료하고 싶습니다

560
00:29:27,919 --> 00:29:33,200
그 아이디어는 스테밍의 핵심입니다

561
00:29:31,279 --> 00:29:37,279
그래서 아무도 없다

562
00:29:33,200 --> 00:29:40,320
텍스트를 줄기로 만드는 올바른 방법 또는 올바른 방법

563
00:29:37,279 --> 00:29:42,480
이 플롯은 세 가지 접근 방식을 보여줍니다.

564
00:29:40,320 --> 00:29:44,880
영어로 어간

565
00:29:42,480 --> 00:29:49,039
헤이부터 시작하여 마지막 s를 제거합시다.

566
00:29:46,240 --> 00:29:51,760
복수에 대한 더 복잡한 규칙

567
00:29:49,039 --> 00:29:54,480
중간에 복수 엔딩 처리

568
00:29:51,760 --> 00:29:57,520
하나는 s 스테머라고합니다

569
00:29:54,480 --> 00:30:01,360
그것은 일종의 규칙의 집합과 같습니다.

570
00:29:58,640 --> 00:30:02,640
그리고 마지막은 가장 잘 알려진

571
00:30:01,360 --> 00:30:04,960
아마도 가장 잘 알려진

572
00:30:02,640 --> 00:30:07,279
영어로 형태소 분석 구현

573
00:30:04,960 --> 00:30:09,919
포터 알고리즘이라고 함

574
00:30:07,279 --> 00:30:12,559
여기에서 Porter가

575
00:30:09,919 --> 00:30:14,880
다른 둘과 가장 다른

576
00:30:12,559 --> 00:30:16,799
여기 데이터에서 상위 20개 단어에

577
00:30:14,880 --> 00:30:19,840
내가 가지고 있는 동물 설명 세트

578
00:30:16,799 --> 00:30:21,520
우리는 종이라는 단어를 사용하여

579
00:30:19,840 --> 00:30:25,600
다른 동물 포식자 취급

580
00:30:24,240 --> 00:30:31,440
이런 종류의 단어 모음

581
00:30:28,240 --> 00:30:33,200
삶을 살아라 치료받은 삶을 살아라

582
00:30:31,440 --> 00:30:38,960
따라서 실무자들은 일반적으로

583
00:30:36,240 --> 00:30:40,559
텍스트 데이터의 형태소 분석에 관심이 있기 때문에

584
00:30:38,960 --> 00:30:46,960
우리가 믿는 토큰을 함께 버킷

585
00:30:43,679 --> 00:30:51,600
하는 방식으로 함께 속해있다.

586
00:30:46,960 --> 00:30:53,360
우리는 인간 사용자로서

587
00:30:51,600 --> 00:30:58,320
우리가 이와 같은 접근 방식을 사용할 수 있도록

588
00:30:56,799 --> 00:31:04,159
단계별로 꽤

589
00:31:01,519 --> 00:31:07,039
이를 기반으로 하는 규칙을 일반적으로

590
00:31:04,159 --> 00:31:09,600
형태소 분석 또는 그것은 상당히

591
00:31:07,039 --> 00:31:12,080
본질적으로 알고리즘 같은

592
00:31:09,600 --> 00:31:14,720
먼저 이렇게 하고 다음에는 이렇게 하세요

593
00:31:12,080 --> 00:31:17,840
또는 표제어를 사용할 수 있습니다

594
00:31:15,519 --> 00:31:23,519
일반적으로 큰 사전을 기반으로 합니다.

595
00:31:19,440 --> 00:31:26,559
단어 및 그것은 다음과 같이 통합됩니다.

596
00:31:23,519 --> 00:31:31,120
어떤 단어가 함께 속해 있는지에 대한 언어적 이해

597
00:31:28,559 --> 00:31:34,960
따라서 대부분의 기존 접근 방식은

598
00:31:31,120 --> 00:31:38,559
이런 종류의 한국어 작업은

599
00:31:35,919 --> 00:31:41,279
다음을 기반으로 하는 제한된 표제어입니다.

600
00:31:38,559 --> 00:31:45,679
사전 및 훈련된 사전

601
00:31:42,480 --> 00:31:47,600
대규모 언어 데이터 세트 사용

602
00:31:45,679 --> 00:31:50,559
도움이 될 것 같습니다.

603
00:31:49,039 --> 00:31:53,360
당신이 이것에 대해 들었을 때 당신은

604
00:31:50,559 --> 00:31:54,880
오 예 좋은 소리, 똑똑한 소리

605
00:31:53,360 --> 00:32:00,480
특히 텍스트 데이터의 경우 일반적으로

606
00:31:56,919 --> 00:32:04,080
많은 토큰이 있는 기능에 압도됨

607
00:32:02,320 --> 00:32:05,840
이것은 일반적으로 상황

608
00:32:04,080 --> 00:32:09,440
텍스트 데이터를 다룰 때

609
00:32:05,840 --> 00:32:16,080
여기에 동물 설명 데이터가 있습니다.

610
00:32:12,080 --> 00:32:18,240
그리고 나는 그것의 행렬 표현을 만들었습니다.

611
00:32:16,080 --> 00:32:20,159
우리가 일반적으로 일부에서 사용하는 것처럼

612
00:32:18,240 --> 00:32:24,000
기계 학습 알고리즘

613
00:32:20,159 --> 00:32:28,880
그리고 얼마나 많은 기능이 있는지 보세요

614
00:32:25,200 --> 00:32:31,600
16,000개 거의 17,000개 기능

615
00:32:29,679 --> 00:32:33,519
그것은 기능의 수입니다

616
00:32:31,600 --> 00:32:36,640
모델에 들어갈 것입니다

617
00:32:33,519 --> 00:32:39,919
희소성을 봐

618
00:32:36,640 --> 00:32:43,440
98% 희소, 매우 높음

619
00:32:39,919 --> 00:32:45,360
희소 데이터이므로 이것은 희소성입니다.

620
00:32:43,440 --> 00:32:47,760
기계에 들어갈 데이터

621
00:32:45,360 --> 00:32:51,600
우리를 구축하기 위한 학습 알고리즘

622
00:32:47,760 --> 00:32:53,760
지도 머신 러닝 모델

623
00:32:51,600 --> 00:32:56,480
우리가 단어를 중단하면

624
00:32:53,760 --> 00:33:00,159
여기에서 형태소 분석에 대한 접근 방식을 사용하면

625
00:32:56,480 --> 00:33:02,240
우리는 다음과 같이 단어 기능의 수를 줄입니다.

626
00:33:00,159 --> 00:33:06,480
수천 개의 희소성이 불행히도

627
00:33:04,640 --> 00:33:09,519
많이 변경하지만 우리는 숫자를 줄였습니다

628
00:33:06,480 --> 00:33:11,600
기능을 버킷팅하여

629
00:33:09,519 --> 00:33:15,200
우리의 형태소 분석 알고리즘이

630
00:33:12,720 --> 00:33:16,880
당신이 알 수 있도록 함께 속해

631
00:33:15,200 --> 00:33:19,519
상식이 말한다

632
00:33:16,880 --> 00:33:21,679
단어 수 줄이기 기능

633
00:33:19,519 --> 00:33:24,880
너무 극적으로 수행 할 것입니다

634
00:33:22,720 --> 00:33:29,039
기계 학습 모델의 성능 향상

635
00:33:26,640 --> 00:33:32,559
그러나 그것은 우리가

636
00:33:29,039 --> 00:33:35,039
중요한 정보를 잃지 않았습니다

637
00:33:32,559 --> 00:33:39,279
형태소 분석을 통해 형태소 분석 또는

638
00:33:37,120 --> 00:33:44,399
표제어는 종종 일부에서 매우 도움이 될 수 있습니다.

639
00:33:41,440 --> 00:33:48,320
컨텍스트가 있지만 이러한 작업에 사용되는 일반적인 알고리즘은

640
00:33:45,519 --> 00:33:51,039
다소 공격적이다

641
00:33:48,320 --> 00:33:53,840
그리고 그들은 감도를 선호하도록 만들어졌습니다.

642
00:33:52,399 --> 00:33:59,279
또는 회상 또는 참 양성률 및

643
00:33:56,880 --> 00:34:01,760
이것은 비용으로

644
00:33:59,279 --> 00:34:04,640
특이성 또는 정밀도 또는 진실

645
00:34:01,760 --> 00:34:07,200
감독되는 기계에서 음수 비율

646
00:34:04,640 --> 00:34:09,679
학습 컨텍스트 이것이 하는 일

647
00:34:07,200 --> 00:34:13,839
모델의 긍정적인 예측에 영향을 줍니다.

648
00:34:11,359 --> 00:34:19,200
정밀도 또는 그 능력에 가치를 둡니다.

649
00:34:16,399 --> 00:34:20,560
참음성 라벨을 잘못 붙이지 않기 위해

650
00:34:19,200 --> 00:34:25,760
내가 옳았으면 좋겠어

651
00:34:22,800 --> 00:34:28,960
그래서 당신은 이것을 더 구체적으로 만들기 위해 알고 있습니다.

652
00:34:25,760 --> 00:34:31,359
형태소 분석은 모델의 능력을 향상시킬 수 있습니다.

653
00:34:28,960 --> 00:34:33,760
긍정적인 사례를 찾기 위해

654
00:34:31,359 --> 00:34:36,320
동물에 대한 설명은

655
00:34:33,760 --> 00:34:38,399
특정 식이요법과 관련된 경우

656
00:34:36,320 --> 00:34:40,720
그것이 우리가 모델링하는 것입니다.

657
00:34:38,399 --> 00:34:43,200
텍스트가 생략되었습니다.

658
00:34:40,720 --> 00:34:45,520
결과 모델은 기능을 잃습니다.

659
00:34:43,200 --> 00:34:47,200
부정적인 예에 레이블을 지정

660
00:34:45,520 --> 00:34:49,760
에 관한 것이 아닌 설명을 말하다

661
00:34:47,200 --> 00:34:52,240
우리가 찾던 바로 그 다이어트

662
00:34:49,760 --> 00:34:54,960
이것은 다음과 같은 경우에 진정한 도전이 될 수 있습니다.

663
00:34:52,240 --> 00:34:57,200
텍스트 데이터 종류의 훈련 모델

664
00:34:54,960 --> 00:34:59,359
그 균형이 거기에 있다는 것을 발견하기 때문에

665
00:34:57,200 --> 00:35:01,280
종종 우리는 가지고 있지 않습니다

666
00:34:59,359 --> 00:35:05,119
우리가 이것을 변경할 수 있는 다이얼

667
00:35:01,280 --> 00:35:08,400
이러한 형태소 분석 알고리즘에 대한 형태소 분석

668
00:35:05,119 --> 00:35:10,800
아주 기본적인 전처리만 해도

669
00:35:08,400 --> 00:35:13,200
내가 여기에 표시하는 것과 같은 텍스트의 경우

670
00:35:10,800 --> 00:35:15,280
이 기능 엔지니어링 레시피는

671
00:35:13,200 --> 00:35:17,440
계산적으로 비싸다

672
00:35:15,280 --> 00:35:20,079
그리고 실무자가 선택하는

673
00:35:17,440 --> 00:35:24,400
제거할지 여부를 결정합니다.

674
00:35:20,079 --> 00:35:27,599
불용어 또는 줄기 텍스트는

675
00:35:24,400 --> 00:35:30,320
머신 러닝 모델에 미치는 영향

676
00:35:27,599 --> 00:35:32,320
모든 종류의

677
00:35:30,320 --> 00:35:34,000
더 간단한 모델

678
00:35:32,320 --> 00:35:36,000
보다 전통적인 기계 학습 모델

679
00:35:34,000 --> 00:35:42,560
또는 딥 러닝 모델이 의미하는 바는

680
00:35:39,040 --> 00:35:45,520
가격 우선 순위 우리가

681
00:35:42,560 --> 00:35:47,920
실무자가 학습을 좋아하는 것처럼

682
00:35:45,520 --> 00:35:50,079
기능에 대해 가르치고 쓰기

683
00:35:47,920 --> 00:35:53,040
텍스트를 위한 엔지니어링 단계

684
00:35:50,079 --> 00:35:56,320
더 나은 견고성에 기여합니다.

685
00:35:53,040 --> 00:35:58,560
우리 분야의 통계 실습

686
00:35:56,320 --> 00:36:01,359
나는 텍스트의 희소성 앞에서 언급했다.

687
00:35:58,560 --> 00:36:04,079
데이터로 돌아가고 싶습니다.

688
00:36:01,359 --> 00:36:06,720
텍스트 데이터 중 하나이기 때문에

689
00:36:04,079 --> 00:36:14,320
언어가 작동하는 방식 때문에 특성 정의

690
00:36:10,400 --> 00:36:16,640
우리는 몇 가지 단어를 많이 사용합니다

691
00:36:14,320 --> 00:36:19,599
그리고 나서 많은 단어들은 단지

692
00:36:16,640 --> 00:36:22,640
몇 번 몇 번만

693
00:36:19,599 --> 00:36:25,119
실제 자연어 세트로

694
00:36:22,640 --> 00:36:27,520
당신은 보이는 관계로 끝납니다

695
00:36:25,119 --> 00:36:30,640
이 플롯처럼 보이는 이와 같이

696
00:36:27,520 --> 00:36:32,400
희소성이 어떻게 변하는지에 대한 용어

697
00:36:30,640 --> 00:36:35,680
더 많은 문서 추가

698
00:36:32,400 --> 00:36:38,320
그리고 말뭉치에 대한 더 독특한 단어

699
00:36:35,680 --> 00:36:43,040
그래서 희소성은 당신만큼 정말 빨리 올라갑니다.

700
00:36:38,320 --> 00:36:45,760
더 독특한 단어와 메모리를 추가

701
00:36:43,040 --> 00:36:51,920
처리하는 데 필요한

702
00:36:48,480 --> 00:36:53,520
이 문서 세트는 매우 빠르게 올라갑니다.

703
00:36:51,920 --> 00:36:57,520
따라서 전문 데이터를 사용하더라도

704
00:36:56,320 --> 00:37:03,280
희소 데이터와 같은 희소 데이터를 저장하기 위한 구조

705
00:37:00,079 --> 00:37:05,920
당신은 여전히 성장하는 매트릭스

706
00:37:03,280 --> 00:37:07,599
이러한 데이터를 처리하는 데 필요한 메모리

707
00:37:05,920 --> 00:37:13,119
매우 비선형적인 방식으로 설정되며 여전히 매우 자랍니다.

708
00:37:09,920 --> 00:37:15,520
매우 빠르므로 매우 오래 걸릴 수 있습니다.

709
00:37:13,119 --> 00:37:19,839
모델을 훈련하는 데 오랜 시간이 걸리거나

710
00:37:16,960 --> 00:37:21,760
당신은 기억을 초과

711
00:37:19,839 --> 00:37:23,839
당신이 가야 할 당신의 기계에서 사용 가능

712
00:37:21,760 --> 00:37:26,079
값비싼 클라우드로

713
00:37:23,839 --> 00:37:31,200
큰 메모리 상황은 이것이 진짜 도전이 될 수 있습니다.

714
00:37:27,680 --> 00:37:34,320
그리고 이 도전

715
00:37:31,200 --> 00:37:39,359
벡터의 동기 부여 뒤에 있는 것입니다.

716
00:37:37,200 --> 00:37:43,520
모델을 위한 언어

717
00:37:40,240 --> 00:37:46,480
언어학자들은 오랫동안 일해 왔다.

718
00:37:43,520 --> 00:37:49,680
할 수 있는 모델을 위한 벡터 언어

719
00:37:46,480 --> 00:37:55,280
텍스트 데이터를 나타내는 차원 수 줄이기

720
00:37:51,680 --> 00:37:58,160
사람들이 언어를 사용하는 방식에 따라

721
00:37:55,280 --> 00:38:04,960
그래서 이 인용문은 1957년으로 거슬러 올라갑니다.

722
00:38:02,960 --> 00:38:09,280
그래서 여기에서 우리가 사용하는 아이디어는

723
00:38:07,119 --> 00:38:12,800
데이터가 매우 희박한 것처럼

724
00:38:09,280 --> 00:38:15,440
하지만 우리는 단어를 사용하지 않습니다

725
00:38:12,800 --> 00:38:17,359
무작위로 독립적이지 않은 단어

726
00:38:15,440 --> 00:38:19,599
서로 독립적으로 사용되지 않음

727
00:38:17,359 --> 00:38:22,240
그러나 오히려 관계가 있습니다.

728
00:38:19,599 --> 00:38:25,920
단어가 함께 사용되는 방식 사이에 존재

729
00:38:23,359 --> 00:38:31,040
이러한 관계를 사용하여

730
00:38:27,599 --> 00:38:33,599
희소한 고차원을 변환하기 위해

731
00:38:31,040 --> 00:38:37,359
특별한 밀도로 공간

732
00:38:34,560 --> 00:38:40,160
낮은 차원 공간

733
00:38:37,359 --> 00:38:42,480
우리는 여전히 100과 같습니다

734
00:38:40,160 --> 00:38:46,160
치수이지만 수천 개보다 훨씬 낮습니다.

735
00:38:44,000 --> 00:38:48,160
수십만 수십만

736
00:38:46,160 --> 00:38:49,839
여기에서 우리가 사용하는 아이디어는

737
00:38:48,160 --> 00:38:55,599
통계 모델링은 아마도

738
00:38:51,839 --> 00:38:58,240
단어 수와 행렬 분해

739
00:38:55,599 --> 00:39:00,480
아마도 신경과 관련된 더 멋진 수학

740
00:38:58,240 --> 00:39:03,680
네트워크를 통해

741
00:39:00,480 --> 00:39:05,839
차원 공간과 우리는 새로운

742
00:39:03,680 --> 00:39:08,480
저차원 저차원

743
00:39:05,839 --> 00:39:12,000
새로워진 특별한 공간

744
00:39:08,480 --> 00:39:15,040
공간은 벡터를 기반으로 생성됩니다.

745
00:39:12,000 --> 00:39:18,560
정보를 통합하다

746
00:39:15,040 --> 00:39:21,839
어떤 단어가 함께 사용되는지에 대해

747
00:39:18,560 --> 00:39:26,480
당신은 그것이 유지하는 회사에 의해 단어를 알게 될 것입니다

748
00:39:24,079 --> 00:39:29,359
따라서 큰 데이터 세트의 텍스트가 필요합니다.

749
00:39:26,480 --> 00:39:32,000
이런 종류의 단어를 만들거나 배우다

750
00:39:29,359 --> 00:39:35,119
벡터 또는 단어 임베딩

751
00:39:32,000 --> 00:39:37,040
그래서 지금 보여드리는 이 테이블은

752
00:39:35,119 --> 00:39:40,560
임베딩 세트에서 가져온 것입니다.

753
00:39:37,040 --> 00:39:48,000
데이터 세트 또는 불만 모음을 사용하여 만들었습니다.

754
00:39:44,640 --> 00:39:51,680
미국 소비자에 대한 불만

755
00:39:49,200 --> 00:39:53,839
금융 보호국

756
00:39:51,680 --> 00:39:56,640
그래서 이것은 정부 기관입니다.

757
00:39:53,839 --> 00:40:00,720
불평하고 말할 수 있는 미국

758
00:39:57,920 --> 00:40:03,680
뭔 상관이야

759
00:40:00,720 --> 00:40:07,599
신용카드와 같은 금융상품

760
00:40:04,720 --> 00:40:09,760
모기지 학자금 대출

761
00:40:07,599 --> 00:40:11,119
금융과 같은 일

762
00:40:09,760 --> 00:40:13,119
그들은 뭔가 갔다와 같은 제품

763
00:40:11,119 --> 00:40:15,359
내 신용 카드에 문제가 생겼습니다.

764
00:40:13,119 --> 00:40:17,520
회사가 가지고 있는 내 모기지와 관련하여 잘못되었습니다.

765
00:40:15,359 --> 00:40:24,000
불공평해서 와서 불평한다

766
00:40:20,000 --> 00:40:27,839
그래서 나는 모든 불만을 받아들이고

767
00:40:25,440 --> 00:40:30,160
그것은 우리의 고차원 공간이고

768
00:40:27,839 --> 00:40:32,400
저차원 공간을 구축

769
00:40:30,160 --> 00:40:37,680
우리는 그 공간을 보고 이해할 수 있습니다.

770
00:40:33,920 --> 00:40:40,240
어떤 단어가 서로 관련이 있는지

771
00:40:37,680 --> 00:40:44,079
이 공간에서 그래서 새로운 공간에서

772
00:40:40,240 --> 00:40:48,000
월이라는 단어 임베딩으로 정의

773
00:40:44,079 --> 00:40:50,880
년 월 복수와 같은 단어에 가장 가깝습니다.

774
00:40:49,680 --> 00:40:56,480
월 할부금 그래서 이것들은 단어입니다

775
00:40:54,560 --> 00:41:01,280
의 맥락에서 의미가 있습니다.

776
00:40:57,839 --> 00:41:05,119
신용 카드 또는 모기지와 같은 금융 상품

777
00:41:03,359 --> 00:41:09,680
이러한 임베딩에 의해 정의된 새로운 공간에서

778
00:41:06,720 --> 00:41:11,760
단어 오류는 단어에 가장 가깝습니다.

779
00:41:09,680 --> 00:41:17,680
사무적 실수처럼 사무적 실수처럼

780
00:41:14,960 --> 00:41:20,880
문제 결함 또는 결함이 내

781
00:41:19,040 --> 00:41:26,240
모기지 명세서

782
00:41:23,440 --> 00:41:28,319
또는 당신을 오해하는 잘못된 의사 소통

783
00:41:26,240 --> 00:41:30,880
이것들은 다음과 같은 단어라는 것을 알고 있습니다.

784
00:41:28,319 --> 00:41:33,599
비슷한 방식으로 사용되므로

785
00:41:31,599 --> 00:41:37,200
임베딩을 직접 만들 필요가 없습니다.

786
00:41:34,800 --> 00:41:39,520
많은 데이터가 필요하기 때문에

787
00:41:37,200 --> 00:41:42,240
단어를 사용할 수 있도록

788
00:41:39,520 --> 00:41:44,880
사전 훈련된 임베딩

789
00:41:42,240 --> 00:41:47,520
즉, 다른 사람이 만든

790
00:41:44,880 --> 00:41:49,839
엄청난 양의 데이터를 기반으로

791
00:41:47,520 --> 00:41:54,079
그들은 접근할 수 있고 당신은 아마 그렇지 않을 것입니다

792
00:41:51,359 --> 00:41:55,599
데이터 세트 중 하나를 살펴보겠습니다.

793
00:41:54,079 --> 00:42:02,800
동일한 단어 오류에 대한 결과를 보여 주는 이 표를 살펴보겠습니다.

794
00:42:00,160 --> 00:42:04,560
하지만 장갑 임베딩의 경우

795
00:42:02,800 --> 00:42:07,359
장갑 임베딩은

796
00:42:04,560 --> 00:42:09,920
생성된 사전 훈련된 임베딩

797
00:42:07,359 --> 00:42:12,800
다음과 같은 매우 큰 데이터 세트를 기반으로

798
00:42:11,040 --> 00:42:16,640
모든 wikipedia 모든 Google 뉴스 데이터 세트

799
00:42:15,280 --> 00:42:24,800
인터넷의 거대한 범위가 그랬던 것처럼

800
00:42:21,440 --> 00:42:27,280
이러한 임베딩을 생성하기 위해

801
00:42:24,800 --> 00:42:31,680
그래서 여기에서 가장 가까운 단어 중 일부는 비슷합니다.

802
00:42:29,520 --> 00:42:34,800
이전에 있지만 우리는 그렇지 않은 사람들에게

803
00:42:31,680 --> 00:42:38,640
더 이상 해당 도메인의 일부가 특정

804
00:42:34,800 --> 00:42:40,839
성직자의 불일치와 같은 맛

805
00:42:38,640 --> 00:42:43,280
이제 우리는 좋아합니다

806
00:42:40,839 --> 00:42:46,720
당신은 알고 있지만 지금 우리는 잘못된 의사 소통

807
00:42:43,280 --> 00:42:48,960
계산과 확률이 있다

808
00:42:46,720 --> 00:42:51,599
사람들이 이야기하지 않은 것

809
00:42:48,960 --> 00:42:54,319
그들의 금융 상품 불만

810
00:42:51,599 --> 00:42:58,240
그래서 이것은 정말 하이라이트

811
00:42:54,319 --> 00:43:00,800
이전에 여기에서 어떻게 작동하는지

812
00:42:58,240 --> 00:43:02,640
우리는 우리 자신의 것을 만들었고 우리는 할 수 있었습니다

813
00:43:00,800 --> 00:43:06,800
있었던 관계를 배우기 위해

814
00:43:02,640 --> 00:43:10,400
이 맥락에 따라 여기에 우리가 간다

815
00:43:06,800 --> 00:43:13,119
더 일반적인 집합으로

816
00:43:10,400 --> 00:43:16,720
다른 곳에서 배웠다

817
00:43:13,119 --> 00:43:19,599
그래서 임베딩은 훈련되거나 학습됩니다.

818
00:43:16,720 --> 00:43:22,079
방대한 양의 텍스트 데이터와

819
00:43:19,599 --> 00:43:24,240
그 말뭉치의 특징은

820
00:43:22,079 --> 00:43:27,359
임베딩의 일부

821
00:43:24,240 --> 00:43:30,160
따라서 일반적으로 기계 학습은

822
00:43:27,359 --> 00:43:32,240
무엇이든 간에 절묘하게 민감하다.

823
00:43:30,160 --> 00:43:35,839
그것은 당신의 훈련 데이터에 있고 이것은

824
00:43:32,240 --> 00:43:38,160
언제보다 더 명확하지 않습니다

825
00:43:35,839 --> 00:43:40,319
텍스트 데이터 다루기

826
00:43:38,160 --> 00:43:42,400
아마도 단어 임베딩은

827
00:43:40,319 --> 00:43:43,760
이 고전적인 예 중 하나처럼

828
00:43:42,400 --> 00:43:48,160
이것이 사실인 경우

829
00:43:46,079 --> 00:43:54,400
이것은 어떤 인간이 어떻게

830
00:43:51,040 --> 00:43:56,480
말뭉치의 편견 또는 편견

831
00:43:54,400 --> 00:44:01,440
임베딩에 각인됩니다.

832
00:43:59,040 --> 00:44:04,720
그래서 사실 우리가 이것들 중 일부를 볼 때

833
00:44:01,440 --> 00:44:07,040
가장 일반적으로 사용 가능한 임베딩

834
00:44:04,720 --> 00:44:14,640
거기에 편견이 있다는 것은 우리가 그것을 볼 수 있다는 것입니다

835
00:44:12,200 --> 00:44:17,520
아프리카계 미국인 이름

836
00:44:14,640 --> 00:44:19,680
아프리카계 미국인에게 더 흔합니다.

837
00:44:17,520 --> 00:44:23,280
그들이 연결된 미국

838
00:44:19,680 --> 00:44:25,520
유럽보다 더 불쾌한 감정

839
00:44:23,280 --> 00:44:30,240
이러한 임베딩 공간의 미국 이름

840
00:44:27,680 --> 00:44:31,599
여성의 이름이 더 관련이 있습니다.

841
00:44:30,240 --> 00:44:38,640
가족 및 남성의 이름은 경력과 더 관련이 있습니다.

842
00:44:36,079 --> 00:44:40,560
여성과 관련된 용어가 더 많습니다.

843
00:44:38,640 --> 00:44:42,640
예술 및 용어와 관련된

844
00:44:40,560 --> 00:44:44,079
남성과 관련된 것이 더 관련이 있습니다.

845
00:44:42,640 --> 00:44:51,440
과학을 사용하면 실제로 편향이 있다는 것이 밝혀졌습니다.

846
00:44:48,319 --> 00:44:54,160
워드 임베딩에 내재된

847
00:44:51,440 --> 00:44:56,800
단어 임베딩 자체를 사용할 수 있습니다.

848
00:44:54,160 --> 00:45:01,440
변화를 정량화하기 위해

849
00:44:58,480 --> 00:45:05,040
시간이 지남에 따라 사회적 태도

850
00:45:01,440 --> 00:45:08,160
그래서 워드 임베딩은

851
00:45:05,040 --> 00:45:11,119
과장되거나 극단적인 예일 수 있습니다.

852
00:45:08,160 --> 00:45:13,599
하지만 모든 기능이

853
00:45:11,119 --> 00:45:16,720
우리가 내리는 엔지니어링 결정

854
00:45:13,599 --> 00:45:18,480
그것은 텍스트 데이터에 오면 중요한

855
00:45:16,720 --> 00:45:21,440
결과에 미치는 영향

856
00:45:18,480 --> 00:45:26,000
우리가 보는 모델 성능 측면에서

857
00:45:22,560 --> 00:45:29,520
또한 얼마나 적절하거나

858
00:45:26,000 --> 00:45:31,599
공정한 우리 모델은

859
00:45:29,520 --> 00:45:34,560
그래서 그것이 올 때 모든 것을 주었다.

860
00:45:31,599 --> 00:45:37,040
텍스트 데이터 전처리

861
00:45:34,560 --> 00:45:39,680
필요한 기능 생성

862
00:45:37,040 --> 00:45:43,520
당신은 많은 옵션과 꽤

863
00:45:39,680 --> 00:45:46,560
약간의 책임이 있으므로 내 조언은

864
00:45:43,520 --> 00:45:50,480
항상 더 간단한 모델로 시작하여

865
00:45:46,560 --> 00:45:50,480
당신은 꽤 깊이 이해할 수 있습니다

866
00:45:50,640 --> 00:45:56,720
좋은 통계를 채택하십시오

867
00:45:53,520 --> 00:45:59,040
훈련하고 조정할 때의 연습

868
00:45:56,720 --> 00:46:04,720
모델에 속지 않도록 모델

869
00:46:01,839 --> 00:46:07,119
성능 향상

870
00:46:04,720 --> 00:46:10,400
다른 접근을 시도할 때

871
00:46:07,119 --> 00:46:12,839
또한 모델 설명 가능성을 사용하기 위해

872
00:46:10,400 --> 00:46:16,079
도구와 프레임워크를 통해

873
00:46:12,839 --> 00:46:18,000
덜 간단하게 이해

874
00:46:16,079 --> 00:46:20,240
당신이 시도하는 모델

875
00:46:18,000 --> 00:46:22,640
그래서 내 동료와 나는 썼다.

876
00:46:20,240 --> 00:46:24,720
이 모든 주제와 방법에 대해

877
00:46:22,640 --> 00:46:26,880
그렇다면 Tidymodels와 함께 사용하십시오.

878
00:46:24,720 --> 00:46:30,319
당신은 사용하기를 좋아하고 우리는 계속 그렇게 할 것입니다

879
00:46:28,720 --> 00:46:33,040
그것으로 나는 말할 것이다

880
00:46:30,319 --> 00:46:34,880
너무너무 감사하고 하고싶습니다

881
00:46:33,040 --> 00:46:38,960
꼭 다시

882
00:46:36,560 --> 00:46:42,560
R 사용자 그룹의 주최자에게 감사

883
00:46:38,960 --> 00:46:45,119
한국에서는 팀원들에게 감사 인사를 전하고 싶습니다.

884
00:46:42,560 --> 00:46:47,440
Rstudio의 Tidymodels 팀은 다음과 같이

885
00:46:45,119 --> 00:46:51,240
제 공동 저자인 EMIL HVITFELDT도 마찬가지입니다.
