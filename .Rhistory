path_filenames <- glue::glue("fig/yolo/{list.files('fig/yolo')}")
path_filenames
yolo_images <- map(yolo_path_filenames, magick::image_read)
yolo_path_filenames <- glue::glue("fig/yolo/{list.files('fig/yolo')}")
yolo_images <- map(yolo_path_filenames, magick::image_read)
yolo_images
yolo_images %>%
image_append()
yolo_images %>%
image_combine()
yolo_images %>%
image_append(stack = TRUE)
yolo_images %>%
image_append(stack = TRUE) %>%
image_animate()
yolo_images %>%
image_append(stack = TRUE) %>%
image_animate(.)
yolo_images %>%
image_append(stack = TRUE) %>%
image_join(.)
yolo_images %>%
image_append(stack = TRUE) %>%
image_join()
yolo_images %>%
image_join()
yolo_images <- map(yolo_path_filenames, magick::image_read %>% resize(200))
yolo_images <- map(yolo_path_filenames, magick::image_read %>% magick::resize(200))
? image_resize
map(yolo_images, magick::image_resize, geometry = 200 )
yolo_images_data <- yolo_images %>%
image_join()
yolo_images_data %>%
image_animate()
? image_animate
yolo_images_data %>%
image_animate(fps = 10)
yolo_images_data %>%
image_animate(fps = 100)
yolo_images_data %>%
image_animate(fps = 1000)
yolo_images_data %>%
image_animate(fps = 500)
yolo_images_data %>%
image_animate(fps = 100)
? image_animate
yolo_images_data %>%
image_animate(fps = 1)
orignal_img <- image_read("data/captcha_dataset/226md.png")
library(tidyvese)
library(magick)
orignal_img <- image_read("data/captcha_dataset/226md.png")
orignal_img
orignal_img %>%
image_convert(colorspace = 'gray') %>%
image_threshold(threshold = "50%", type = "white") %>%
image_deskew() %>%
# image_morphology(method = "Thinning", kernel = "Rectangle:20x1+0+0^<") %>%
image_morphology('Dilate', "Diamond", iterations = 2)
orignal_img %>%
image_resize("377px")
orignal_img %>%
image_resize("377p")
orignal_img %>%
image_resize("377x")
orignal_img
orignal_img %>%
image_resize("377x")
orignal_img %>%
image_convert(colorspace = 'gray') %>%
image_threshold(threshold = "50%", type = "white") %>%
image_deskew() %>%
image_morphology('Dilate', "Diamond", iterations = 2)  %>%
image_resize("377x")
install.packages("text2speech")
library(text2speech)
if (requireNamespace("aws.polly", quietly = TRUE)) {
if ( tts_auth("amazon")) {
df = tts_voices(service = "amazon")
knitr::kable(df)
}
}
install.packages("aws.polly")
if (requireNamespace("aws.polly", quietly = TRUE)) {
if ( tts_auth("amazon")) {
df = tts_voices(service = "amazon")
knitr::kable(df)
}
}
tts_auth("amazon")
library(aws.polly)
aws.polly::list_voices()
? aws.polly::list_voices()
usethis::edit_r_environ()
? Startup
readRenviron("C:/Users/statkclee/Documents/.Renviron")
tts_auth("amazon")
if (requireNamespace("aws.polly", quietly = TRUE)) {
if ( tts_auth("amazon")) {
df = tts_voices(service = "amazon")
knitr::kable(df)
}
}
library(aws.polly)
tts_auth("amazon")
aws_df  <- tts_voices(service = "amazon")
aws_df
aws_df  <- tts_voices(service = "amazon") %>%
as_tibble
library(tidyverse)
library(tidyverse)
library(text2speech)
library(aws.polly)
tts_auth("amazon")
aws_df  <- tts_voices(service = "amazon") %>%
as_tibble
aws_df
aws_df %>%
filter(str_detect(language, "Korean"))
readRenviron("~/Documents/.Renviron")
readRenviron("~/.Renviron")
## Google -------------------------------------
library(googleLanguageR)
if (tts_google_auth()) {
df = tts_voices(service = "google")
print(head(df))
}
df
tts_voices(service = "google")
tts_google_auth()
readRenviron("~/.Renviron")
tts_google_auth()
tts_voices(service = "google")
google_df <- tts_voices(service = "google")
google_df <- tts_voices(service = "google") %>%
as_tibble()
google_df
google_df %>%
mutate(language = str_to_lower(language)) %>%
filter(str_detect(language, "korean"))
aws_df %>%
filter(str_detect(language, "Korean"))
library("tuneR")
usethis::edit_r_environ()
vec <- synthesize("데이터 과학자 이광춘님 환영합니다.", voice = "Seoyeon")
library("tuneR")
play(vec)
list_lexicon()
? synthesize
korean_mp3 <- synthesize("데이터 과학자 이광춘님 환영합니다.",
voice = "Seoyeon",
format = "mp3",
rate = 22050)
# On Mac OSX: setWavPlayer("/usr/bin/afplay")
# On Linux systems, try: setWavPlayer("/usr/bin/aplay")
setWavPlayer("C:/Program Files/Window Media Player/wmplayer.exe")
play(korean_synthesis)
korean_synthesis <- synthesize("데이터 과학자 이광춘님 환영합니다.", voice = "Seoyeon")
library("tuneR")
# On Mac OSX: setWavPlayer("/usr/bin/afplay")
# On Linux systems, try: setWavPlayer("/usr/bin/aplay")
setWavPlayer("C:/Program Files/Window Media Player/wmplayer.exe")
play(korean_synthesis)
play(korean_synthesis)
library("tuneR")
play(korean_synthesis)
# Chunk 1: setup
knitr::opts_chunk$set(echo = TRUE, message=FALSE, warning=FALSE,
comment="", digits = 3, tidy = FALSE, prompt = FALSE, fig.align = 'center')
knitr::opts_knit$set(global.par = TRUE)
# Chunk 2: tts-cloud-services-aws-polly
library(tidyverse)
library(text2speech)
readRenviron("~/.Renviron")
## AWS -------------------------------------
library(aws.polly)
tts_auth("amazon")
aws_df  <- tts_voices(service = "amazon") %>%
as_tibble
aws_df %>%
filter(str_detect(language, "Korean"))
# Chunk 3: tts-cloud-services-google-language
## Google -------------------------------------
library(googleLanguageR)
tts_google_auth()
google_df <- tts_voices(service = "google") %>%
as_tibble()
google_df %>%
mutate(language = str_to_lower(language)) %>%
filter(str_detect(language, "korean"))
# Chunk 4: aws-polly-helloworld
korean_synthesis <- synthesize("데이터 과학자 이광춘님 환영합니다.", voice = "Seoyeon")
library("tuneR")
# On Mac OSX: setWavPlayer("/usr/bin/afplay")
# On Linux systems, try: setWavPlayer("/usr/bin/aplay")
# setWavPlayer("C:/Program Files/Window Media Player/wmplayer.exe")
play(korean_synthesis)
# Chunk 5: aws-polly-mp3
korean_mp3 <- synthesize("데이터 과학자 이광춘님 환영합니다.",
voice = "Seoyeon",
format = "mp3",
rate = 22050)
# Chunk 1: setup
knitr::opts_chunk$set(echo = TRUE, message=FALSE, warning=FALSE,
comment="", digits = 3, tidy = FALSE, prompt = FALSE, fig.align = 'center')
knitr::opts_knit$set(global.par = TRUE)
# Chunk 2: tts-cloud-services-aws-polly
library(tidyverse)
library(text2speech)
readRenviron("~/.Renviron")
## AWS -------------------------------------
library(aws.polly)
tts_auth("amazon")
aws_df  <- tts_voices(service = "amazon") %>%
as_tibble
aws_df %>%
filter(str_detect(language, "Korean"))
# Chunk 3: tts-cloud-services-google-language
## Google -------------------------------------
library(googleLanguageR)
tts_google_auth()
google_df <- tts_voices(service = "google") %>%
as_tibble()
google_df %>%
mutate(language = str_to_lower(language)) %>%
filter(str_detect(language, "korean"))
# Chunk 4: aws-polly-helloworld
korean_synthesis <- synthesize("데이터 과학자 이광춘님 환영합니다.", voice = "Seoyeon")
library("tuneR")
# On Mac OSX: setWavPlayer("/usr/bin/afplay")
# On Linux systems, try: setWavPlayer("/usr/bin/aplay")
# setWavPlayer("C:/Program Files/Window Media Player/wmplayer.exe")
play(korean_synthesis)
# Chunk 5: aws-polly-mp3
korean_mp3 <- synthesize("데이터 과학자 이광춘님 환영합니다.",
voice = "Seoyeon",
format = "mp3",
rate = 22050)
tuneR::writeWave(korean_synthesis, "data/hello_world.wav")
System("dir")
system("dir")
system("ffmepg")
devtools::install_github("mccarthy-m-g/embedr")
devtools::install_github("mccarthy-m-g/embedr")
library(embedr)
embed_audio("data/hello_world.mp3")
devtools::install_github("gadenbuie/xaringanExtra")
devtools::install_github("gadenbuie/xaringanExtra")
devtools::install_github("gadenbuie/xaringanExtra")
install.packages("digest")
install.packages("digest")
devtools::install_github("gadenbuie/xaringanExtra")
xaringan::inf_mr()
OCR_res <- ariExtra::rmd_to_ari(
ari::ari_example("xaringan-OCR.Rmd"),
capture_method = "iterative", open = FALSE)
OCR_res <- ariExtra::rmd_to_ari(
"xaringan-OCR.Rmd",
capture_method = "iterative", open = FALSE)
library(tidyverse)
slides_text <- read_lines("xaringan-OCR.Rmd")
str_extract(slides_text, pattern = "??? .* ---")
library(tidyverse)
slides_text <- read_lines("xaringan-OCR.Rmd")
str_extract(slides_text, pattern = "??? .* ---")
str_extract(slides_text, pattern = "\\?\\?\\? .* ---")
str_extract(slides_text, pattern = "\\?\\?\\?.*---")
str_extract_all(slides_text, pattern = "\?\?\?.*---")
str_extract_all(slides_text, pattern = "\\(???).*---")
str_extract_all(slides_text, pattern = "(\\???).*---")
str_extract_all(slides_text, pattern = "(\\?\\?\\?).*---")
str_extract_all(slides_text, pattern = "(\\?{3}).*---")
str_extract_all(slides_text, pattern = "\\?{3}.*---")
str_extract_all(slides_text, pattern = "\\?{3}.*")
str_extract_all(slides_text, pattern = "\\?{3}\n.*")
str_extract_all(slides_text, pattern = "\\?{3}[\r\n].*")
str_extract_all(slides_text, pattern = "\\?{3}[\r\n].*---[\r\n]")
str_extract_all(slides_text, pattern = "\\?{3}[\\r\\n].*---")
str_extract_all(slides_text, pattern = "\\?{3}.*---")
slides_text
? read_lines
stringr::str_glue(slides_text)
stringr::str_glue("{slides_text}")
stringr::str_glue("{slides_text}") %>%
str_extract_all(., pattern = "\\?{3}.*---")
stringr::str_glue("{slides_text}") %>%
str_extract_all(., pattern = "\\?{3}.*")
stringr::str_glue("{slides_text}") %>%
str_extract_all(., pattern = "\\?{3}[\\r\\n].*")
stringr::str_glue("{slides_text}") %>%
str_extract_all(., pattern = "\\?{3}.*")
stringr::str_glue("{slides_text}")
stringr::str_glue("{slides_text}") %>%
str_extract_all(., pattern = "(?<=\\?{3})(.*)(?=---)")
?str_glue
stringr::str_glue("{slides_text}", sep=" ") %>%
str_extract_all(., pattern = "(?<=\\?{3})(.*)(?=---)")
stringr::str_glue("{slides_text}", sep=" ")
stringr::str_glue("{slides_text}", sep="") %>%
str_extract_all(., pattern = "(?<=\\?{3})(.*)(?=---)")
stringr::str_glue("{slides_text}", sep="")
stringr::str_glue("{slides_text}", sep="") %>%
str_extract_all(., pattern = "(?<=\\?{3})(.*)")
paste0(slides_text, collapse = "")
paste0(slides_text, collapse = "") %>%
str_extract_all(., pattern = "(?<=\\?{3})(.*)(?=---)")
paste0(slides_text, collapse = " ") %>%
str_extract_all(., pattern = "(?<=\\?{3})(.*)(?=---)")
paste0(slides_text, collapse = " ") %>%
str_extract(., pattern = "(?<=\\?{3})(.*)(?=---)")
paste0(slides_text, collapse = " ") %>%
str_extract(., pattern = "(?<=\\?{3} )(.*)(?=---)")
paste0(slides_text, collapse = " ") %>%
str_extract(., pattern = "(?<=\\?{3} )(.*)(?= ---)")
paste0(slides_text, collapse = " ") %>%
str_extract(., pattern = "(?<=class )(.*)(?=left)")
paste0(slides_text, collapse = " ") %>%
str_extract(., pattern = "(?<=class)(.*)(?=left)")
paste0(slides_text, collapse = " ") %>%
str_extract_all(., pattern = "(?<=class)(.*)(?=left)")
paste0(slides_text, collapse = " ") %>%
str_extract_all(., pattern = "(?<=\\\?\?\\?)(.*)(?=left)")
paste0(slides_text, collapse = " ") %>%
str_extract_all(., pattern = "(?<=\\?\\?\\?)(.*)(?=left)")
paste0(slides_text, collapse = " ") %>%
str_extract_all(., pattern = "(?<=\\?\\?\\?)(.*)(?=---)")
paste0(slides_text, collapse = " ") %>%
str_extract_all(., pattern = "(?<=\\?\\?\\?)(.*\n)(?=---)")
paste0(slides_text, collapse = " ") %>%
str_extract_all(., pattern = "(?<=\\?\\?\\?)(.*)(?=---)")
paste0(slides_text, collapse = " ") %>%
str_extract_all(., pattern = "(?<=\\?\\?\\?)(.*?)(?=---)")
ocr_scripts <- paste0(slides_text, collapse = " ") %>%
str_extract_all(., pattern = "(?<=\\?\\?\\?)(.*?)(?=---)")
ocr_scripts
paste0(slides_text, collapse = " ") %>%
str_extract_all(., pattern = "(?<=\\?\\?\\?)(.*?)")
paste0(slides_text, collapse = " ") %>%
str_extract_all(., pattern = "(?<=\\?\\?\\?)(\w+)$")
paste0(slides_text, collapse = " ") %>%
str_extract_all(., pattern = "(?<=\\?\\?\\?)(\\w+)$")
paste0(slides_text, collapse = " ") %>%
str_extract_all(., pattern = "(?<=\\?\\?\\?)\\w+$")
paste0(slides_text, collapse = " ") %>%
str_extract_all(., pattern = "\\w+$")
paste0(slides_text, collapse = " ") %>%
str_extract_all(., pattern = "\\s(\\w+)$")
paste0(slides_text, collapse = " ")
paste0(slides_text, collapse = " ") %>%
str_extract_all(., pattern = "[^/]+$")
paste0(slides_text, collapse = " ") %>%
str_extract_all(., pattern = "(?<=\\?\\?\\?)+$")
paste0(slides_text, collapse = " ") %>%
str_extract_all(., pattern = "(?<=\\?\\?\\?)(.*?)$")
paste0(slides_text, collapse = " ") %>%
str_extract_all(., pattern = "[^\\?\\?\\?]+$")
final_scripts <- str_c(ocr_scripts, last_script)
library(tidyverse)
slides_text <- read_lines("xaringan-OCR.Rmd")
ocr_scripts <- paste0(slides_text, collapse = " ") %>%
str_extract_all(., pattern = "(?<=\\?\\?\\?)(.*?)(?=---)")
last_script <- paste0(slides_text, collapse = " ") %>%
str_extract_all(., pattern = "[^\\?\\?\\?]+$")
final_scripts <- str_c(ocr_scripts, last_script)
ocr_scripts
last_script
last_script <- paste0(slides_text, collapse = " ") %>%
str_extract_all(., pattern = "[^\\?\\?\\?]+$") %>%
.[[1]]
final_scripts <- str_c(ocr_scripts, last_script)
final_scripts
final_scripts <- c(ocr_scripts, last_script)
final_scripts
final_scripts <- append(ocr_scripts, last_script)
final_scripts
final_scripts <- c(ocr_scripts, last_script)
c(ocr_scripts, last_script)
ocr_scripts[length(ocr_scripts)+1] <-  last_script)
ocr_scripts[length(ocr_scripts)+1] <-  last_script
ocr_scripts
last_script <- paste0(slides_text, collapse = " ") %>%
str_extract_all(., pattern = "[^\\?\\?\\?]+$") %>%
.[[1]]
last_script
ocr_scripts[length(ocr_scripts)+1] <-  last_script
ocr_scripts
library(tidyverse)
slides_text <- read_lines("xaringan-OCR.Rmd")
ocr_scripts <- paste0(slides_text, collapse = " ") %>%
str_extract_all(., pattern = "(?<=\\?\\?\\?)(.*?)(?=---)")
last_script <- paste0(slides_text, collapse = " ") %>%
str_extract_all(., pattern = "[^\\?\\?\\?]+$") %>%
.[[1]]
ocr_scripts[length(ocr_scripts)+1] <-  last_script
ocr_scripts
library(tidyverse)
slides_text <- read_lines("xaringan-OCR.Rmd")
ocr_scripts <- paste0(slides_text, collapse = " ") %>%
str_extract_all(., pattern = "(?<=\\?\\?\\?)(.*?)(?=---)")
last_script <- paste0(slides_text, collapse = " ") %>%
str_extract_all(., pattern = "[^\\?\\?\\?]+$") %>%
.[[1]]
ocr_scripts[length(ocr_scripts)+1] <- last_script
ocr_scripts
c(ocr_scripts)
library(tidyverse)
slides_text <- read_lines("xaringan-OCR.Rmd")
ocr_scripts <- paste0(slides_text, collapse = " ") %>%
str_extract_all(., pattern = "(?<=\\?\\?\\?)(.*?)(?=---)")
last_script <- paste0(slides_text, collapse = " ") %>%
str_extract_all(., pattern = "[^\\?\\?\\?]+$") %>%
.[[1]]
# ocr_scripts[length(ocr_scripts)+1] <- last_script
c(ocr_scripts, last_script)
c(ocr_scripts, last_script) %>%
unlist
# ocr_scripts[length(ocr_scripts)+1] <- last_script
final_script <- c(ocr_scripts, last_script) %>%
unlist
pagedown::chrome_print("xaringan-OCR.html",output="xaringan-OCR.pdf")
install.packages("pagedown")
pagedown::chrome_print("xaringan-OCR.html",output="xaringan-OCR.pdf")
remotes::install_github('rstudio/pagedown')
remotes::install_github('rstudio/pagedown')
# remotes::install_github('rstudio/pagedown')
pagedown::chrome_print("xaringan-OCR.html",output="xaringan-OCR.pdf")
# remotes::install_github('rstudio/pagedown')
# pagedown::chrome_print("xaringan-OCR.html",output="xaringan-OCR.pdf")
# Windows Error
# Error in force(expr) :
#   Failed to generate output. Reason: Failed to open https://fonts.googleapis.com/css?family=Nanum+Gothic:300,300i&display=swap (HTTP status code: 400)
xaringan::decktape("xaringan-OCR.html", output="xaringan-OCR.pdf",
docker = FALSE)
? decktape
# remotes::install_github('rstudio/pagedown')
# pagedown::chrome_print("xaringan-OCR.html",output="xaringan-OCR.pdf")
# Windows Error
# Error in force(expr) :
#   Failed to generate output. Reason: Failed to open https://fonts.googleapis.com/css?family=Nanum+Gothic:300,300i&display=swap (HTTP status code: 400)
xaringan::decktape("xaringan-OCR.html", output="xaringan-OCR.pdf",
docker = TRUE)
magick::image_read_pdf("xaringan-OCR.pdf")
xaringan_ocr_pdf <- pdf_convert("data/xaringan-OCR.pdf",format = 'png',verbose = FALSE)
library(pdftools)
# remotes::install_github('rstudio/pagedown')
# pagedown::chrome_print("xaringan-OCR.html",output="xaringan-OCR.pdf")
# Windows Error
# Error in force(expr) :
#   Failed to generate output. Reason: Failed to open https://fonts.googleapis.com/css?family=Nanum+Gothic:300,300i&display=swap (HTTP status code: 400)
# xaringan::decktape("xaringan-OCR.html", output="xaringan-OCR.pdf",
#                    docker = TRUE)
# Error in xaringan::decktape("xaringan-OCR.html", output = "xaringan-OCR.pdf",  :
#   Failed to convert xaringan-OCR.html to PDF
xaringan_ocr_pdf <- pdf_convert("data/xaringan-OCR.pdf",format = 'png',verbose = FALSE)
xaringan_ocr_pdf
library(pdftools)
library(slickR)
# remotes::install_github('rstudio/pagedown')
# pagedown::chrome_print("xaringan-OCR.html",output="xaringan-OCR.pdf")
# Windows Error
# Error in force(expr) :
#   Failed to generate output. Reason: Failed to open https://fonts.googleapis.com/css?family=Nanum+Gothic:300,300i&display=swap (HTTP status code: 400)
# xaringan::decktape("xaringan-OCR.html", output="xaringan-OCR.pdf",
#                    docker = TRUE)
# Error in xaringan::decktape("xaringan-OCR.html", output = "xaringan-OCR.pdf",  :
#   Failed to convert xaringan-OCR.html to PDF
xaringan_ocr_pdf <- pdf_convert("data/xaringan-OCR.pdf",format = 'png',verbose = FALSE)
xaringan_pdf_df <- tibble(page = glue::glue("data/{xaringan_ocr_pdf}") )
slickR(xaringan_pdf_df$page, height = 600)
library(tidyverse)
xaringan_pdf_df <- tibble(page = glue::glue("data/{xaringan_ocr_pdf}") )
slickR(xaringan_pdf_df$page, height = 600)
xaringan_ocr_pdf
xaringan_ocr_pdf[1,3:10]
xaringan_ocr_pdf[c(1,3:10)]
xaringan_pdf_df <- tibble(page = glue::glue("data/{xaringan_ocr_pdf[c(1,3:10)]}") )
slickR(xaringan_pdf_df$page, height = 600)
xaringan_pdf_df <-
write_rds("data/xaringan_pdf_df.rds")
xaringan_pdf_df %>%
write_rds("data/xaringan_pdf_df.rds")
xaringan_pdf_df$page
ari_spin(
xaringan_pdf_df$page,
final_script,
output = "data/xaringan_OCR.mp4",
voice = "Seoyeon",
divisible_height = TRUE, subtitles = TRUE)
library(ari)
ari_spin(
xaringan_pdf_df$page,
final_script,
output = "data/xaringan_OCR.mp4",
voice = "Seoyeon",
divisible_height = TRUE, subtitles = TRUE)
xaringan_pdf_df$page
length(xaringan_pdf_df$page)
length(final_script)
final_script
xaringan_pdf_df <- tibble(page = glue::glue("data/{xaringan_ocr_pdf[c(1,3:11)]}") )
xaringan_pdf_df %>%
write_rds("data/xaringan_pdf_df.rds")
xaringan_pdf_df <-
read_rds("data/xaringan_pdf_df.rds")
slickR(xaringan_pdf_df$page, height = 600)
ari_spin(
xaringan_pdf_df$page,
final_script,
output = "data/xaringan_OCR.mp4",
voice = "Seoyeon",
divisible_height = TRUE, subtitles = TRUE)
final_script
